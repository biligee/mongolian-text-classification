{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mongolian text classification #02, word2vec initialization, trainable embedding matrix.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "muNP8k9fqaJb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mongolian text classification series #01\n",
        "\n",
        "In this notebook I'm gonna try to classify cyrillic mongolian texts with word2vec initialization, facebook's pretrained word2vec weights will be used.  \n",
        "\n",
        "Eduge dataset provided by Bolorsoft LLC\n",
        "\n",
        "Author : Sharavsambuu Gunchinish (sharavsambuu@gmail.com)\n",
        "\n",
        "Github: https://github.com/sharavsambuu/mongolian-text-classification \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "iY9jwdg6qT8M",
        "colab_type": "code",
        "outputId": "b79b5a3d-dcf3-4dac-b5d9-34649e35ec7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "!pip install gensim\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.130)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.0)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.130 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.130)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "smJeJfoo4qcu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[More info about creation of eduge dataset pickles](https://github.com/sharavsambuu/mongolian-text-classification/blob/master/preprocess_dataset/preprocess_eduge.ipynb) preprocessing eats a lot of CPU cycle so it's good idea to cook it before using colab."
      ]
    },
    {
      "metadata": {
        "id": "CDayX_Yx3REh",
        "colab_type": "code",
        "outputId": "8812e624-433e-4055-979d-7c09eacbdbba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "import sys\n",
        "\n",
        "def download_from_google_drive(file_id, file_name):\n",
        "  !rm -f ./cookie\n",
        "  !curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=$file_id\" > /dev/null\n",
        "  confirm_text = !awk '/download/ {print $NF}' ./cookie\n",
        "  confirm_text = confirm_text[0]\n",
        "  !curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=$confirm_text&id=$file_id\" -o $file_name\n",
        "  \n",
        "# download eduge pickles\n",
        "file_path = 'eduge_pickles'\n",
        "if not exists(file_path):\n",
        "  download_from_google_drive('1vjJ9YgIe8o0ErhbN0lH1XqPv3KFP8acv', '%s.rar' % file_path)\n",
        "  rar_file = file_path+\".rar\"\n",
        "  !unrar x $rar_file"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   388    0   388    0     0   2811      0 --:--:-- --:--:-- --:--:--  2811\n",
            "100  106M    0  106M    0     0   116M      0 --:--:-- --:--:-- --:--:--  230M\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from eduge_pickles.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file word_index.pickle\n",
            "9178153 bytes, modified on 2019-04-13 01:44\n",
            "with a new one\n",
            "9178153 bytes, modified on 2019-04-13 01:44\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit q\n",
            "\n",
            "Program aborted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pPHJcnfi4Rzg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('word_index.pickle', 'rb') as handle:\n",
        "  word_index = pickle.load(handle)\n",
        "    \n",
        "with open('reversed_word_index.pickle', 'rb') as handle:\n",
        "  reversed_word_index = pickle.load(handle)\n",
        "  \n",
        "with open('eduge_stopwords_removed.pickle', 'rb') as handle:\n",
        "  eduge_ds = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ASRW7ISNnbM-",
        "colab_type": "code",
        "outputId": "93977ac0-16cf-4c71-e0ea-f88e956d4fa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "# facebook trained word2vec on both commoncrawl and wikipedia. So this model should contain enough representation about our mongolian words.\n",
        "mongolian_word2vec_download=\"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.mn.300.bin.gz\"\n",
        "if not exists(\"cc.mn.300.bin.gz\"):\n",
        "  !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.mn.300.bin.gz\n",
        "  !gunzip cc.mn.300.bin.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-13 08:46:45--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.mn.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2937042399 (2.7G) [application/octet-stream]\n",
            "Saving to: ‘cc.mn.300.bin.gz’\n",
            "\n",
            "cc.mn.300.bin.gz    100%[===================>]   2.73G  28.4MB/s    in 2m 5s   \n",
            "\n",
            "2019-04-13 08:48:51 (22.3 MB/s) - ‘cc.mn.300.bin.gz’ saved [2937042399/2937042399]\n",
            "\n",
            "gzip: cc.mn.300.bin already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BqGAauUZpnFz",
        "colab_type": "code",
        "outputId": "dbf9ecb4-5a0e-4832-b3b5-73f691e61e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.wrappers import FastText\n",
        "\n",
        "word2vec_model = FastText.load_fasttext_format('cc.mn.300.bin')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0413 08:50:53.198039 139727675725696 ssh.py:33] paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
            "W0413 08:50:53.441090 139727675725696 word2vec.py:573] Slow version of gensim.models.deprecated.word2vec is being used\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kkc1iiqJp-CJ",
        "colab_type": "code",
        "outputId": "67437a67-71db-4357-b272-e778b8685340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "print(word2vec_model.most_similar('монгол'))\n",
        "#print(word2vec_model[\"монгол\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Монгол', 0.6342526078224182), ('монголын', 0.6047513484954834), ('хятад', 0.5558866858482361), ('Монголын', 0.5087883472442627), ('судлалаараа', 0.48851606249809265), ('манай', 0.4853793680667877), ('уйгаржин', 0.4725492596626282), ('угсаатангууд', 0.47093287110328674), ('орос', 0.46463483572006226), ('худам', 0.4609120190143585)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oF6vB3Qnq08I",
        "colab_type": "code",
        "outputId": "7ce374e4-e934-442f-839f-3a4310815135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# preparing embedding matrix\n",
        "import numpy as np\n",
        "\n",
        "words_not_found = []\n",
        "embed_dim       = 300\n",
        "embedding_matrix = np.random.uniform(-1, 1, (len(word_index), embed_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i<4:\n",
        "    continue\n",
        "  try:\n",
        "    embedding_vector = word2vec_model[word]\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "      # words not found in embedding index will be all-zeros.\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "  except:\n",
        "    words_not_found.append(word)\n",
        "    pass\n",
        "print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of null word embeddings: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aQAaXWIgsxm9",
        "colab_type": "code",
        "outputId": "2552baed-3c8c-423c-ae68-c9aa4d661e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(embedding_matrix.shape)\n",
        "#print(embedding_matrix[5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(370794, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XFxd1QGR65VV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512\n",
        "\n",
        "import itertools\n",
        "\n",
        "for item in eduge_ds:\n",
        "  item[0] = list(itertools.chain(*item[0]))[:MAX_LEN]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U8PTeX0WCbhR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(eduge_ds, test_size=0.1, random_state=999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8mgMCFcgDHH4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_words  = [i[0] for i in train]\n",
        "train_label_words = [i[1] for i in train]\n",
        "test_data_words   = [i[0] for i in test ]\n",
        "test_label_words  = [i[1] for i in test ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rrXC7UiuFkCH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def encode_news(text):\n",
        "    return [word_index.get(i, 2) for i in text]\n",
        "  \n",
        "train_data = [encode_news(sent) for sent in train_data_words]\n",
        "test_data  = [encode_news(sent) for sent in test_data_words ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FV-h_avPEzM1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=MAX_LEN)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDVqmPqxIMid",
        "colab_type": "code",
        "outputId": "499dbc96-6834-4892-e75d-2f4470687315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "labels = list(set(test_label_words))\n",
        "labels"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['спорт',\n",
              " 'эдийн засаг',\n",
              " 'байгал орчин',\n",
              " 'улс төр',\n",
              " 'боловсрол',\n",
              " 'урлаг соёл',\n",
              " 'эрүүл мэнд',\n",
              " 'технологи',\n",
              " 'хууль']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "PBKj3GQqJq29",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder     = LabelBinarizer()\n",
        "train_label = transfomed_label = encoder.fit_transform(train_label_words)\n",
        "test_label  = transfomed_label = encoder.fit_transform(test_label_words )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DPq45PN5HZ15",
        "colab_type": "code",
        "outputId": "5b7a12dc-539d-4988-ef2d-d0922d3602cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_index)\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, embed_dim, weights=[embedding_matrix], input_length=MAX_LEN, trainable=True))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(embed_dim, activation='relu'))\n",
        "model.add(keras.layers.Dense(len(labels), activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 512, 300)          111238200 \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 300)               90300     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 9)                 2709      \n",
            "=================================================================\n",
            "Total params: 111,331,209\n",
            "Trainable params: 111,331,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cAgP1KlqHu2F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPw8roFQKrHm",
        "colab_type": "code",
        "outputId": "063a27d2-6e4a-46e8-c488-0920e4a10a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(train_data), len(train_label))\n",
        "print(len(test_data ), len(test_label) )\n",
        "\n",
        "partial_index = 3000\n",
        "\n",
        "x_val = train_data[:partial_index]\n",
        "partial_x_train = train_data[partial_index:]\n",
        "\n",
        "y_val = train_label[:partial_index]\n",
        "partial_y_train = train_label[partial_index:]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68094 68094\n",
            "7567 7567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iSTB4--RKacs",
        "colab_type": "code",
        "outputId": "c18c19cc-2b66-4716-fee2-cf549dd84962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2801
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 150\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 65094 samples, validate on 3000 samples\n",
            "Epoch 1/150\n",
            "65094/65094 [==============================] - 18s 282us/sample - loss: 1.7890 - accuracy: 0.3554 - val_loss: 1.0611 - val_accuracy: 0.7177\n",
            "Epoch 2/150\n",
            "65094/65094 [==============================] - 17s 259us/sample - loss: 0.6561 - accuracy: 0.8329 - val_loss: 0.5236 - val_accuracy: 0.8693\n",
            "Epoch 3/150\n",
            "65094/65094 [==============================] - 17s 263us/sample - loss: 0.3849 - accuracy: 0.8974 - val_loss: 0.4244 - val_accuracy: 0.8803\n",
            "Epoch 4/150\n",
            "65094/65094 [==============================] - 17s 262us/sample - loss: 0.2882 - accuracy: 0.9218 - val_loss: 0.3990 - val_accuracy: 0.8857\n",
            "Epoch 5/150\n",
            "65094/65094 [==============================] - 17s 268us/sample - loss: 0.2275 - accuracy: 0.9376 - val_loss: 0.3785 - val_accuracy: 0.8900\n",
            "Epoch 6/150\n",
            "65094/65094 [==============================] - 18s 269us/sample - loss: 0.1821 - accuracy: 0.9500 - val_loss: 0.3745 - val_accuracy: 0.8890\n",
            "Epoch 7/150\n",
            "65094/65094 [==============================] - 17s 265us/sample - loss: 0.1444 - accuracy: 0.9599 - val_loss: 0.3827 - val_accuracy: 0.8960\n",
            "Epoch 8/150\n",
            "65094/65094 [==============================] - 17s 262us/sample - loss: 0.1165 - accuracy: 0.9664 - val_loss: 0.3906 - val_accuracy: 0.8940\n",
            "Epoch 9/150\n",
            "65094/65094 [==============================] - 17s 262us/sample - loss: 0.0924 - accuracy: 0.9732 - val_loss: 0.3995 - val_accuracy: 0.8957\n",
            "Epoch 10/150\n",
            "65094/65094 [==============================] - 17s 262us/sample - loss: 0.0759 - accuracy: 0.9780 - val_loss: 0.4198 - val_accuracy: 0.8903\n",
            "Epoch 11/150\n",
            "65094/65094 [==============================] - 17s 263us/sample - loss: 0.0628 - accuracy: 0.9808 - val_loss: 0.4365 - val_accuracy: 0.8910\n",
            "Epoch 12/150\n",
            "65094/65094 [==============================] - 17s 262us/sample - loss: 0.0542 - accuracy: 0.9828 - val_loss: 0.4608 - val_accuracy: 0.8893\n",
            "Epoch 13/150\n",
            "65094/65094 [==============================] - 17s 261us/sample - loss: 0.0465 - accuracy: 0.9850 - val_loss: 0.4707 - val_accuracy: 0.8917\n",
            "Epoch 14/150\n",
            "65094/65094 [==============================] - 17s 268us/sample - loss: 0.0411 - accuracy: 0.9860 - val_loss: 0.4874 - val_accuracy: 0.8940\n",
            "Epoch 15/150\n",
            "65094/65094 [==============================] - 17s 268us/sample - loss: 0.0370 - accuracy: 0.9868 - val_loss: 0.5016 - val_accuracy: 0.8913\n",
            "Epoch 16/150\n",
            "65094/65094 [==============================] - 18s 269us/sample - loss: 0.0341 - accuracy: 0.9878 - val_loss: 0.5204 - val_accuracy: 0.8947\n",
            "Epoch 17/150\n",
            "65094/65094 [==============================] - 18s 270us/sample - loss: 0.0330 - accuracy: 0.9879 - val_loss: 0.5573 - val_accuracy: 0.8867\n",
            "Epoch 18/150\n",
            "65094/65094 [==============================] - 17s 269us/sample - loss: 0.0307 - accuracy: 0.9882 - val_loss: 0.5657 - val_accuracy: 0.8910\n",
            "Epoch 19/150\n",
            "65094/65094 [==============================] - 17s 267us/sample - loss: 0.0292 - accuracy: 0.9887 - val_loss: 0.5712 - val_accuracy: 0.8863\n",
            "Epoch 20/150\n",
            "65094/65094 [==============================] - 18s 270us/sample - loss: 0.0277 - accuracy: 0.9890 - val_loss: 0.5725 - val_accuracy: 0.8923\n",
            "Epoch 21/150\n",
            "65094/65094 [==============================] - 17s 269us/sample - loss: 0.0262 - accuracy: 0.9895 - val_loss: 0.5799 - val_accuracy: 0.8907\n",
            "Epoch 22/150\n",
            "65094/65094 [==============================] - 17s 265us/sample - loss: 0.0245 - accuracy: 0.9897 - val_loss: 0.5874 - val_accuracy: 0.8913\n",
            "Epoch 23/150\n",
            "65094/65094 [==============================] - 17s 263us/sample - loss: 0.0248 - accuracy: 0.9897 - val_loss: 0.6187 - val_accuracy: 0.8857\n",
            "Epoch 24/150\n",
            "65094/65094 [==============================] - 17s 264us/sample - loss: 0.0236 - accuracy: 0.9897 - val_loss: 0.6106 - val_accuracy: 0.8890\n",
            "Epoch 25/150\n",
            "65094/65094 [==============================] - 17s 263us/sample - loss: 0.0228 - accuracy: 0.9901 - val_loss: 0.6224 - val_accuracy: 0.8860\n",
            "Epoch 26/150\n",
            "65094/65094 [==============================] - 17s 264us/sample - loss: 0.0229 - accuracy: 0.9900 - val_loss: 0.6194 - val_accuracy: 0.8873\n",
            "Epoch 27/150\n",
            "65094/65094 [==============================] - 17s 264us/sample - loss: 0.0221 - accuracy: 0.9902 - val_loss: 0.6197 - val_accuracy: 0.8903\n",
            "Epoch 28/150\n",
            "65094/65094 [==============================] - 17s 263us/sample - loss: 0.0209 - accuracy: 0.9903 - val_loss: 0.6258 - val_accuracy: 0.8910\n",
            "Epoch 29/150\n",
            "65094/65094 [==============================] - 17s 262us/sample - loss: 0.0212 - accuracy: 0.9905 - val_loss: 0.6344 - val_accuracy: 0.8900\n",
            "Epoch 30/150\n",
            "65094/65094 [==============================] - 17s 265us/sample - loss: 0.0195 - accuracy: 0.9909 - val_loss: 0.6521 - val_accuracy: 0.8883\n",
            "Epoch 31/150\n",
            "65094/65094 [==============================] - 17s 262us/sample - loss: 0.0198 - accuracy: 0.9906 - val_loss: 0.6537 - val_accuracy: 0.8913\n",
            "Epoch 32/150\n",
            "65094/65094 [==============================] - 17s 264us/sample - loss: 0.0200 - accuracy: 0.9905 - val_loss: 0.6625 - val_accuracy: 0.8910\n",
            "Epoch 33/150\n",
            "65094/65094 [==============================] - 17s 263us/sample - loss: 0.0197 - accuracy: 0.9908 - val_loss: 0.6673 - val_accuracy: 0.8907\n",
            "Epoch 34/150\n",
            "65094/65094 [==============================] - 17s 265us/sample - loss: 0.0187 - accuracy: 0.9912 - val_loss: 0.6635 - val_accuracy: 0.8873\n",
            "Epoch 35/150\n",
            "65094/65094 [==============================] - 17s 264us/sample - loss: 0.0191 - accuracy: 0.9906 - val_loss: 0.6579 - val_accuracy: 0.8913\n",
            "Epoch 36/150\n",
            "65094/65094 [==============================] - 17s 264us/sample - loss: 0.0178 - accuracy: 0.9911 - val_loss: 0.6803 - val_accuracy: 0.8870\n",
            "Epoch 37/150\n",
            "65094/65094 [==============================] - 17s 263us/sample - loss: 0.0186 - accuracy: 0.9910 - val_loss: 0.6677 - val_accuracy: 0.8883\n",
            "Epoch 38/150\n",
            "65094/65094 [==============================] - 17s 262us/sample - loss: 0.0186 - accuracy: 0.9910 - val_loss: 0.6694 - val_accuracy: 0.8917\n",
            "Epoch 39/150\n",
            "65094/65094 [==============================] - 17s 262us/sample - loss: 0.0174 - accuracy: 0.9912 - val_loss: 0.6804 - val_accuracy: 0.8893\n",
            "Epoch 40/150\n",
            "65094/65094 [==============================] - 17s 263us/sample - loss: 0.0171 - accuracy: 0.9914 - val_loss: 0.6817 - val_accuracy: 0.8933\n",
            "Epoch 41/150\n",
            "65094/65094 [==============================] - 17s 264us/sample - loss: 0.0171 - accuracy: 0.9910 - val_loss: 0.6793 - val_accuracy: 0.8937\n",
            "Epoch 42/150\n",
            "65094/65094 [==============================] - 17s 263us/sample - loss: 0.0171 - accuracy: 0.9909 - val_loss: 0.7056 - val_accuracy: 0.8883\n",
            "Epoch 43/150\n",
            "65094/65094 [==============================] - 17s 262us/sample - loss: 0.0169 - accuracy: 0.9915 - val_loss: 0.7003 - val_accuracy: 0.8877\n",
            "Epoch 44/150\n",
            "65094/65094 [==============================] - 17s 266us/sample - loss: 0.0174 - accuracy: 0.9912 - val_loss: 0.7133 - val_accuracy: 0.8887\n",
            "Epoch 45/150\n",
            "65094/65094 [==============================] - 17s 264us/sample - loss: 0.0167 - accuracy: 0.9912 - val_loss: 0.7210 - val_accuracy: 0.8850\n",
            "Epoch 46/150\n",
            "65094/65094 [==============================] - 17s 263us/sample - loss: 0.0167 - accuracy: 0.9912 - val_loss: 0.7263 - val_accuracy: 0.8893\n",
            "Epoch 47/150\n",
            "65094/65094 [==============================] - 17s 262us/sample - loss: 0.0165 - accuracy: 0.9917 - val_loss: 0.7116 - val_accuracy: 0.8897\n",
            "Epoch 48/150\n",
            "65094/65094 [==============================] - 18s 270us/sample - loss: 0.0168 - accuracy: 0.9912 - val_loss: 0.7072 - val_accuracy: 0.8883\n",
            "Epoch 49/150\n",
            "65094/65094 [==============================] - 17s 263us/sample - loss: 0.0158 - accuracy: 0.9919 - val_loss: 0.7451 - val_accuracy: 0.8853\n",
            "Epoch 50/150\n",
            "65094/65094 [==============================] - 17s 263us/sample - loss: 0.0160 - accuracy: 0.9919 - val_loss: 0.7291 - val_accuracy: 0.8887\n",
            "Epoch 51/150\n",
            "64000/65094 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9915"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f63bf567fa9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    871\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "r8_mvDjYL3CX",
        "colab_type": "code",
        "outputId": "1877bc9c-44bd-4215-c9b6-0f5e01f93959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_label)\n",
        "print(results)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7567/7567 [==============================] - 1s 106us/sample - loss: 0.7150 - accuracy: 0.8900\n",
            "[0.7149569996989189, 0.8900489]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VaIioR7EPfig",
        "colab_type": "code",
        "outputId": "f63f7c25-975c-4d31-bf82-c17f22226d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "data_index   = 12\n",
        "data_words   = \" \".join(test_data_words[data_index])\n",
        "data_indexes = test_data[data_index]\n",
        "print(data_words)\n",
        "\n",
        "predicted = model.predict([[data_indexes]])\n",
        "print(encoder.classes_[np.argmax(predicted)])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "спортын төв ордонд өнөөдөр азийн оюутны аварга шалгаруулах эмэгтэй волейболчдын хоёр дахь удаагийн тэмцээний талаар мэдээлэл хийлээ анхны тэмцээн онд тайландын бангконг хотноо болж хоёрдугаар тэмцээнийг азийн оюутны спортын холбооноос аосх олгосон эрхийн дагуу оны дөрөвдүгээр сарын ны өдрүүдэд монгол улсын нийслэл улаанбаатар хотноо зохион байгуулах тэмцээний эрхийг монгол улс оны тавдугаар сарын хуралдсан аосхны гүйцэтгэх хорооны хурлаар хоёр оронтой өрсөлдөн авчээ уг тэмцээнийг монгол улсад авах талаар мосхолбоо оноос санаачлага гарган хөөцөлдөж эхэлсэн тэмцээний эрхийг авахад муын засгийн газрын санхүүгийн дэмжлэг мэргэжлийн холбоодын ажлын туршлага манай улсын олон улсын нэр хүнд ихээхэн тус хүргэжээ зохион байгуулах хороог с ламбаа удирдаж тэмцээний зохион байгуулах хороог збх эрүүл мэндийн сайдын оны тоот тушаалаар батлаж даргаар уихын гишүүн монголын волейболын холбооны мвх хүндэт ерөнхийлөгч сламбаа ажиллаж збхны орлогч даргаар згхагентлагбтсгын дарга чнаранбаатар збхны нарийн бичгийн даргаар монголын оюутны спортын холбооны мосх ерөнхий нарийн бичгийн дарга джаргалсайхан збхны гишүүдэд бсшуяны төрийн нарийн бичгийн дарга ддалайжаргал нийслэлийн здтгазрын дарга цболдсайхан сяны газрын дарга дбатжаргал гхяамны консулын газрын дарга дганхуяг бсшуяны мэргэжлийн боловсролын газрын дарга мбаасанжав гихалбаны дарга дмөрөн мосхны ерөнхийлөгч оуосхны ерөнхий санхүүч дбаясгалан муисийн ректор стөмөрочир мубисийн ректор бжадамба залуу монгол корпорацийн ерөнхийлөгч мсономпил мохны ерөнхий нарийн бичгийн дарга нбямбагэрэл мвхолбооны ерөнхий нарий бичгийн дарга цбатэнх миат хкийн маркетинг борлуулатын хэлтсийн дарга тмэндсайхан боловсрол суваг телевизийн ерөнхий захирал аамундра нар сонгогдон ажиллаж тэмцээнийг үнэ төлбөргүй үзүүлнэ волейболын болон оюутны спортыг сурталчилах дэлгэрүүлэх үүднээс тэмцээнийг үнэ төлбөргүй үзүүлэхээр збхорооны анхдугаар хурлаас шийдвэрлэсэн нийслэлийн иргэдийг тэмцээнийг өргөнөөр үзэхийг здтгазраас уриалсан тэмцээнийг зөвхөн улаанбаатар хотын иргэд бус аймгаас волейболын спортыг сонирхон хөгжөөн дэмжигч үзэгч волейболын спортын мэргэжилтэн багш нар секцэнд хичээллэгч хүүхдүүд зохион байгуулалтай ирэхээр ялангуяа тэмцээн болох газартай хамгийн ойрхон хануул дүүргийн здтгазар дүүргийнхээ ард иргэд хөдөлмөрчид сургуулийн сурагчид оюутнууд цэргийн албан хаагчид буянтухаа орчимын албан байгууллага хамт олныг идэвхтэй оролцуулах арга хэмжээ авч эхлэжээ олон зуун оюутнууд тэмцээн үзэх боллоо тэмцээний өдрүүдэд нийслэлээс буянтухаагийн спортын ордонг чиглэсэн хүмүүсийн цуваа ихсэх төлөвтэй учир нийслэлд үйл ажиллагаа явуулж байгаа орчим идсийн оюутнууд тэмцээнийг анги сургууль хамт олноороо үзэх сонирхолтой байгаагаа монголын оюутны холбоо биеийн тамирын тэнхимдээ хүсчээ үүний дагуу бсшуяам мох монголын оюутны спортын холбоо мосх ноос тэмцээнийг өдөр бүр гаруй сургуулийн орчим оюутнууд нэгдсэн хуваарийн дагуу үзэх хуваарийг бсшуяны төрийн нарийн бичгийн дарга зохион байгуулах үндэсний хороо збх ны гишүүн ддалайжаргал батлан сургуулиудад албан тоотоор хүргүүлжээ мосхд тэмцээнийг үзэхээр олон арван сургуулиуд оюутны тоогоо өгч бүртгүүлж суудлын хувиарлалтанд орж байгаа ажээ ялангуяа биеийн тамирын мэргэжлийн дээд сургуулийн оюутнууд дадлага хичээлээ тэмцээний үеэр хийхээр хичээлийн хувиараа зохицуулсан нийслэлийн засаг дарга оюутнуудад туслав улаанбаатар хотноо болдог оюутны олон улс тив дэлхийн тэмцээн бүрт нийслэлийн засаг дарга гмөнхбаяр ихээхэн туслалцаа үзүүлэн оюутан залуусаа байнга дэмжин оролцдог ажээ тэрээр тус тэмцээнд оролцохоор бэлтгэж байгаа монголын оюутны шигшээ багийн тамирчидын хоногийн бэлтгэл сургалтын зардлыг хариуцан гаргасан хөрөнгө санхүүгийн хүндрэлтэй байгаа үеэд тэмцээнд бэлтгэж байгаа оюутан тамирчидаа цагаа олж хэрэгцээтэй үеэд дэмжлээ мосхолбоо монголын волейболын холбоо мвх тамирчидынхаа өмнөөс талархал илэрхийлжээ монголын баг тамирчид эрдэнэт хотод оны сарын өдрөөс эхлэн хоногийн бэлтгэл хийснийхээ дараа ийнхүү нийслэлийн засаг даргын туслалцаатайгаар гадаадын тамирчидтай хамт байрлах цэцэг зочид буудалдаа орж бэлтгэл сургуулиалтаа үргэлжүүлэх боломжтой нздтгазраас баг\n",
            "спорт\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
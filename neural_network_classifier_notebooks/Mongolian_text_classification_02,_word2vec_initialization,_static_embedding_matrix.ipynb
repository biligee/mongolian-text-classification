{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mongolian text classification #02, word2vec initialization, static embedding matrix.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "muNP8k9fqaJb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mongolian text classification series #01\n",
        "\n",
        "In this notebook I'm gonna try to classify cyrillic mongolian texts with word2vec initialization, facebook's pretrained word2vec weights will be used.  \n",
        "\n",
        "Eduge dataset provided by Bolorsoft LLC\n",
        "\n",
        "Author : Sharavsambuu Gunchinish (sharavsambuu@gmail.com)\n",
        "\n",
        "Github: https://github.com/sharavsambuu/mongolian-text-classification \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "iY9jwdg6qT8M",
        "colab_type": "code",
        "outputId": "49748839-f55e-446d-f9c9-e4bf2fd68359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "!pip install gensim\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.1)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.130)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.3.9)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.0)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.130 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.130)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "smJeJfoo4qcu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[More info about creation of eduge dataset pickles](https://github.com/sharavsambuu/mongolian-text-classification/blob/master/preprocess_dataset/preprocess_eduge.ipynb) preprocessing eats a lot of CPU cycle so it's good idea to cook it before using colab."
      ]
    },
    {
      "metadata": {
        "id": "CDayX_Yx3REh",
        "colab_type": "code",
        "outputId": "217b9ea9-deb2-4f3b-fad2-d456c426b388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "import sys\n",
        "\n",
        "def download_from_google_drive(file_id, file_name):\n",
        "  !rm -f ./cookie\n",
        "  !curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=$file_id\" > /dev/null\n",
        "  confirm_text = !awk '/download/ {print $NF}' ./cookie\n",
        "  confirm_text = confirm_text[0]\n",
        "  !curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=$confirm_text&id=$file_id\" -o $file_name\n",
        "  \n",
        "# download eduge pickles\n",
        "file_path = 'eduge_pickles'\n",
        "if not exists(file_path):\n",
        "  download_from_google_drive('1vjJ9YgIe8o0ErhbN0lH1XqPv3KFP8acv', '%s.rar' % file_path)\n",
        "  rar_file = file_path+\".rar\"\n",
        "  !unrar x $rar_file"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   388    0   388    0     0   2984      0 --:--:-- --:--:-- --:--:--  2984\n",
            "100  106M    0  106M    0     0   116M      0 --:--:-- --:--:-- --:--:--  116M\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from eduge_pickles.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file word_index.pickle\n",
            "9178153 bytes, modified on 2019-04-13 01:44\n",
            "with a new one\n",
            "9178153 bytes, modified on 2019-04-13 01:44\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit q\n",
            "\n",
            "Program aborted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pPHJcnfi4Rzg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('word_index.pickle', 'rb') as handle:\n",
        "  word_index = pickle.load(handle)\n",
        "    \n",
        "with open('reversed_word_index.pickle', 'rb') as handle:\n",
        "  reversed_word_index = pickle.load(handle)\n",
        "  \n",
        "with open('eduge_stopwords_removed.pickle', 'rb') as handle:\n",
        "  eduge_ds = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ASRW7ISNnbM-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "205a3d0f-8e85-48c0-8e9e-2db1cb3eb533"
      },
      "cell_type": "code",
      "source": [
        "# facebook trained word2vec on both commoncrawl and wikipedia. So this model should contain enough representation about our mongolian words.\n",
        "mongolian_word2vec_download=\"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.mn.300.bin.gz\"\n",
        "if not exists(\"cc.mn.300.bin.gz\"):\n",
        "  !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.mn.300.bin.gz\n",
        "  !gunzip cc.mn.300.bin.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-13 07:40:10--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.mn.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2937042399 (2.7G) [application/octet-stream]\n",
            "Saving to: ‘cc.mn.300.bin.gz’\n",
            "\n",
            "cc.mn.300.bin.gz    100%[===================>]   2.73G  27.9MB/s    in 1m 41s  \n",
            "\n",
            "2019-04-13 07:41:51 (27.8 MB/s) - ‘cc.mn.300.bin.gz’ saved [2937042399/2937042399]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BqGAauUZpnFz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f14847e5-18c5-4180-ec6f-285f7337f2ac"
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.wrappers import FastText\n",
        "\n",
        "word2vec_model = FastText.load_fasttext_format('cc.mn.300.bin')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0413 07:43:49.155202 140348932761472 ssh.py:33] paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
            "W0413 07:43:49.536088 140348932761472 word2vec.py:573] Slow version of gensim.models.deprecated.word2vec is being used\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kkc1iiqJp-CJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "fa52891e-7d81-47d8-f40c-ad99f5607eae"
      },
      "cell_type": "code",
      "source": [
        "print(word2vec_model.most_similar('монгол'))\n",
        "#print(word2vec_model[\"монгол\"])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Монгол', 0.6342526078224182), ('монголын', 0.6047513484954834), ('хятад', 0.5558866858482361), ('Монголын', 0.5087883472442627), ('судлалаараа', 0.48851606249809265), ('манай', 0.4853793680667877), ('уйгаржин', 0.4725492596626282), ('угсаатангууд', 0.47093287110328674), ('орос', 0.46463483572006226), ('худам', 0.4609120190143585)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oF6vB3Qnq08I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a405e6e-749a-45f7-aabf-8860e522898c"
      },
      "cell_type": "code",
      "source": [
        "# preparing embedding matrix\n",
        "import numpy as np\n",
        "\n",
        "words_not_found = []\n",
        "embed_dim       = 300\n",
        "embedding_matrix = np.random.uniform(-1, 1, (len(word_index), embed_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i<4:\n",
        "    continue\n",
        "  try:\n",
        "    embedding_vector = word2vec_model[word]\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "      # words not found in embedding index will be all-zeros.\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "  except:\n",
        "    words_not_found.append(word)\n",
        "    pass\n",
        "print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of null word embeddings: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aQAaXWIgsxm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        },
        "outputId": "905e65a0-064b-4aec-d5da-a3866ecf819b"
      },
      "cell_type": "code",
      "source": [
        "print(embedding_matrix.shape)\n",
        "#print(embedding_matrix[5])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(370794, 300)\n",
            "[-1.05637871e-02 -2.08224468e-02 -9.15830198e-04 -8.30183830e-03\n",
            "  9.11077426e-04  9.29622073e-03  3.47890495e-03  7.40211690e-03\n",
            "  1.29913762e-02 -2.28701718e-03  3.09971930e-03  2.61653843e-03\n",
            "  9.35615599e-03 -6.32976706e-04 -1.44581655e-02  8.83297715e-03\n",
            " -6.13231072e-03  1.04775308e-02  1.19179329e-02  6.72390871e-03\n",
            "  1.04715759e-02 -1.16485776e-02  8.95684352e-05 -1.05829490e-02\n",
            " -6.46159798e-03 -9.41502955e-03  9.76312812e-03 -4.39939508e-03\n",
            " -5.60690090e-03 -6.08651107e-03 -1.55586125e-02  7.06539676e-03\n",
            " -1.42321270e-03 -8.99509992e-03  1.04483729e-02  8.31610896e-03\n",
            " -4.51149972e-04 -5.54138934e-03  2.79903202e-03  5.56980027e-04\n",
            "  1.65209528e-02  2.00354122e-02  7.43129430e-03 -1.37951663e-02\n",
            " -7.00565055e-04 -4.40782728e-03 -8.72603850e-04 -7.60663627e-03\n",
            "  1.29072955e-02  5.86537318e-03  8.94303620e-03 -3.35041224e-03\n",
            " -5.27137145e-03 -3.46761080e-03 -9.28205252e-03  2.71191285e-03\n",
            " -1.02881091e-02  5.94624365e-03 -5.10198297e-03  1.34274065e-02\n",
            "  6.25230023e-04 -6.69540651e-03 -8.75649683e-04  1.02412119e-03\n",
            "  8.83307029e-03 -9.42571554e-03 -5.02432557e-03  1.80750701e-03\n",
            "  1.19467289e-03  4.56332648e-03  1.70588598e-03 -1.18396534e-02\n",
            " -5.56875626e-03  3.17403954e-03  2.05702358e-03 -8.35566968e-03\n",
            "  8.12867470e-03  4.07137768e-03  9.71167814e-03  7.59730581e-04\n",
            "  1.40053378e-02  2.55319267e-03 -3.93030746e-03  1.22684427e-02\n",
            " -7.80537538e-03  2.90662679e-03  4.31739073e-03  3.31274024e-03\n",
            "  1.58350375e-02 -7.33318226e-03  6.75417297e-03  3.21155484e-03\n",
            "  2.39984388e-03  3.74968932e-03  9.12186876e-03 -1.14668673e-02\n",
            "  9.46094375e-03  3.32590402e-03 -2.35140952e-03 -4.79655759e-03\n",
            " -4.24847752e-03  5.06854570e-03 -6.71863602e-03 -5.89298317e-03\n",
            "  1.64016783e-02  5.70298545e-03  7.91425537e-03  2.43782342e-04\n",
            "  4.79783863e-03  3.26307770e-03  6.70094462e-03  2.94254441e-03\n",
            " -8.50607827e-03  2.00263481e-03 -1.57734286e-02  1.17372125e-02\n",
            "  5.06681250e-03  4.90826694e-03 -4.43245081e-04 -7.46611645e-03\n",
            "  2.00629439e-02  3.16196494e-03  2.66721239e-04 -4.67312429e-03\n",
            " -6.51769200e-03  9.09279659e-03  4.31658002e-03  1.82622205e-02\n",
            "  1.02847274e-02 -6.96124649e-03 -1.46406947e-03 -4.13080095e-04\n",
            " -3.80641897e-03  3.48551053e-04  2.78777909e-03  3.93292727e-03\n",
            "  2.42194710e-05  2.45638727e-03 -1.01255188e-02 -7.93735308e-05\n",
            " -5.04712202e-03 -5.75113669e-03 -7.23938970e-03  5.04279218e-04\n",
            "  1.46781616e-02  5.94528345e-03  3.02827306e-04 -6.83662528e-03\n",
            " -1.03935488e-02  3.51659395e-03  5.30596683e-03 -6.17192185e-04\n",
            " -1.02215977e-02 -1.34371640e-02  3.10237519e-03  3.86095163e-03\n",
            " -1.10881953e-02 -1.59364042e-03  3.42684798e-03 -2.38083885e-03\n",
            " -3.34060774e-03 -1.73129700e-03 -2.60342564e-02 -6.95559382e-03\n",
            "  1.34671209e-02 -6.86952285e-03  2.50294834e-04 -1.97883532e-03\n",
            "  3.05590848e-03 -1.82151403e-02  5.76632889e-03  8.67031422e-03\n",
            " -8.52816179e-03  1.59104653e-02  1.19202686e-02  2.22244975e-03\n",
            " -8.19005631e-03  5.97871654e-03  1.51556090e-03  5.71807660e-03\n",
            " -2.70795939e-03 -1.05938008e-02 -6.14651153e-03  1.32346461e-02\n",
            " -5.36749000e-03 -1.21313883e-02 -7.62528181e-03  1.10226208e-02\n",
            " -7.76719814e-03 -5.14597818e-03  2.97629461e-03 -2.15075095e-03\n",
            " -6.39805710e-03 -1.31051708e-03  1.69547589e-03 -5.44780679e-03\n",
            " -1.23001719e-02 -1.01504382e-03 -3.46554746e-03 -3.18726455e-03\n",
            " -3.41553986e-03  4.96459613e-03  8.48843623e-03 -5.95402031e-04\n",
            "  1.13572851e-02 -5.03063062e-03  5.85726323e-03 -3.23636108e-03\n",
            " -3.41105647e-03 -1.41757317e-02 -2.49265670e-03 -2.28565303e-03\n",
            "  9.07063484e-03  4.26557759e-04  1.05492333e-02 -5.73735358e-03\n",
            " -1.14658950e-02 -5.79815730e-03 -9.65505093e-03  9.46741272e-03\n",
            " -8.00311659e-03 -3.05274763e-04 -4.58997121e-04 -1.32533105e-03\n",
            "  4.63666022e-03 -1.14657811e-03  4.02035704e-03  2.21317704e-03\n",
            " -2.06832513e-02 -8.10886361e-03  6.79791719e-03 -1.43847626e-03\n",
            "  6.91626593e-03  1.03996589e-03 -6.47963258e-04 -5.17738378e-03\n",
            "  5.41758083e-04  6.57832576e-03 -6.79499237e-03 -4.87340800e-03\n",
            "  4.57808888e-03 -1.05860606e-02  1.10047741e-03  2.07579341e-02\n",
            "  1.53973140e-03  5.98916830e-03 -3.56168696e-03 -4.01203102e-03\n",
            "  3.78005975e-03 -7.09903135e-04 -2.93715019e-03 -2.81171221e-03\n",
            " -7.16644758e-03  5.85924834e-03 -4.49135434e-03 -5.90154529e-03\n",
            "  4.31835046e-03 -3.94943543e-03  9.80626792e-04  9.23183002e-03\n",
            " -1.66450290e-03  7.14025600e-03 -3.31222336e-03 -3.69819696e-03\n",
            "  4.61361418e-03  5.59566496e-03  4.57737502e-03  1.17390007e-02\n",
            "  1.06747411e-02  2.71064043e-03  1.24668842e-02 -1.29054138e-03\n",
            "  2.33658701e-02  4.93649486e-03  4.79069585e-03 -1.28348696e-03\n",
            " -1.01281209e-02 -5.67259407e-03 -9.65297397e-04  1.20794401e-02\n",
            " -8.36699922e-03  5.52215474e-03  3.18337069e-03  7.75804147e-05\n",
            " -4.66279336e-04  1.34172104e-02 -7.15799816e-03  8.12600367e-04\n",
            "  1.41697973e-02 -1.39529860e-04 -1.04605616e-03  5.68304397e-03\n",
            " -7.95074552e-03 -7.54347246e-04 -1.18307313e-02  3.38693638e-03\n",
            "  4.03297180e-03  7.27922609e-03  9.00964439e-03 -1.67682767e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XFxd1QGR65VV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512\n",
        "\n",
        "import itertools\n",
        "\n",
        "for item in eduge_ds:\n",
        "  item[0] = list(itertools.chain(*item[0]))[:MAX_LEN]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U8PTeX0WCbhR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(eduge_ds, test_size=0.1, random_state=999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8mgMCFcgDHH4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_words  = [i[0] for i in train]\n",
        "train_label_words = [i[1] for i in train]\n",
        "test_data_words   = [i[0] for i in test ]\n",
        "test_label_words  = [i[1] for i in test ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rrXC7UiuFkCH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def encode_news(text):\n",
        "    return [word_index.get(i, 2) for i in text]\n",
        "  \n",
        "train_data = [encode_news(sent) for sent in train_data_words]\n",
        "test_data  = [encode_news(sent) for sent in test_data_words ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FV-h_avPEzM1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=MAX_LEN)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDVqmPqxIMid",
        "colab_type": "code",
        "outputId": "a6ade5b6-36ce-4f44-a0d6-82d5521108b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "labels = list(set(test_label_words))\n",
        "labels"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['байгал орчин',\n",
              " 'улс төр',\n",
              " 'хууль',\n",
              " 'урлаг соёл',\n",
              " 'боловсрол',\n",
              " 'спорт',\n",
              " 'эдийн засаг',\n",
              " 'технологи',\n",
              " 'эрүүл мэнд']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "PBKj3GQqJq29",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder     = LabelBinarizer()\n",
        "train_label = transfomed_label = encoder.fit_transform(train_label_words)\n",
        "test_label  = transfomed_label = encoder.fit_transform(test_label_words )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DPq45PN5HZ15",
        "colab_type": "code",
        "outputId": "02513aa8-3308-4802-95e7-f4b60fc2da90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_index)\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, embed_dim, weights=[embedding_matrix], input_length=MAX_LEN, trainable=False))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(embed_dim, activation='relu'))\n",
        "model.add(keras.layers.Dense(len(labels), activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 512, 300)          111238200 \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 300)               90300     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 9)                 2709      \n",
            "=================================================================\n",
            "Total params: 111,331,209\n",
            "Trainable params: 93,009\n",
            "Non-trainable params: 111,238,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cAgP1KlqHu2F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPw8roFQKrHm",
        "colab_type": "code",
        "outputId": "f3e10da0-8dbd-4540-e762-303f21081882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(train_data), len(train_label))\n",
        "print(len(test_data ), len(test_label) )\n",
        "\n",
        "partial_index = 3000\n",
        "\n",
        "x_val = train_data[:partial_index]\n",
        "partial_x_train = train_data[partial_index:]\n",
        "\n",
        "y_val = train_label[:partial_index]\n",
        "partial_y_train = train_label[partial_index:]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68094 68094\n",
            "7567 7567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iSTB4--RKacs",
        "colab_type": "code",
        "outputId": "aefba085-ab19-4720-8d2c-ffc012db37c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5154
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 150\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 65094 samples, validate on 3000 samples\n",
            "Epoch 1/150\n",
            "65094/65094 [==============================] - 2s 34us/sample - loss: 1.2211 - accuracy: 0.6209 - val_loss: 1.2301 - val_accuracy: 0.6160\n",
            "Epoch 2/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.2091 - accuracy: 0.6277 - val_loss: 1.2222 - val_accuracy: 0.6193\n",
            "Epoch 3/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.1974 - accuracy: 0.6332 - val_loss: 1.2195 - val_accuracy: 0.6423\n",
            "Epoch 4/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.1884 - accuracy: 0.6338 - val_loss: 1.2081 - val_accuracy: 0.6047\n",
            "Epoch 5/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.1761 - accuracy: 0.6379 - val_loss: 1.1940 - val_accuracy: 0.6207\n",
            "Epoch 6/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.1666 - accuracy: 0.6414 - val_loss: 1.1870 - val_accuracy: 0.6197\n",
            "Epoch 7/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.1585 - accuracy: 0.6427 - val_loss: 1.1790 - val_accuracy: 0.6377\n",
            "Epoch 8/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.1487 - accuracy: 0.6470 - val_loss: 1.1640 - val_accuracy: 0.6317\n",
            "Epoch 9/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.1389 - accuracy: 0.6511 - val_loss: 1.1710 - val_accuracy: 0.6097\n",
            "Epoch 10/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.1337 - accuracy: 0.6515 - val_loss: 1.1512 - val_accuracy: 0.6367\n",
            "Epoch 11/150\n",
            "65094/65094 [==============================] - 2s 33us/sample - loss: 1.1220 - accuracy: 0.6581 - val_loss: 1.1384 - val_accuracy: 0.6527\n",
            "Epoch 12/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.1159 - accuracy: 0.6562 - val_loss: 1.1327 - val_accuracy: 0.6373\n",
            "Epoch 13/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.1075 - accuracy: 0.6587 - val_loss: 1.1490 - val_accuracy: 0.6120\n",
            "Epoch 14/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.1011 - accuracy: 0.6616 - val_loss: 1.1218 - val_accuracy: 0.6433\n",
            "Epoch 15/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0950 - accuracy: 0.6610 - val_loss: 1.1125 - val_accuracy: 0.6530\n",
            "Epoch 16/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 1.0866 - accuracy: 0.6681 - val_loss: 1.1055 - val_accuracy: 0.6570\n",
            "Epoch 17/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0822 - accuracy: 0.6663 - val_loss: 1.1020 - val_accuracy: 0.6727\n",
            "Epoch 18/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0729 - accuracy: 0.6707 - val_loss: 1.1026 - val_accuracy: 0.6323\n",
            "Epoch 19/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0684 - accuracy: 0.6711 - val_loss: 1.0999 - val_accuracy: 0.6403\n",
            "Epoch 20/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0612 - accuracy: 0.6750 - val_loss: 1.0819 - val_accuracy: 0.6540\n",
            "Epoch 21/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0546 - accuracy: 0.6764 - val_loss: 1.0806 - val_accuracy: 0.6503\n",
            "Epoch 22/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0495 - accuracy: 0.6790 - val_loss: 1.0688 - val_accuracy: 0.6700\n",
            "Epoch 23/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0436 - accuracy: 0.6782 - val_loss: 1.0673 - val_accuracy: 0.6697\n",
            "Epoch 24/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0388 - accuracy: 0.6806 - val_loss: 1.0686 - val_accuracy: 0.6547\n",
            "Epoch 25/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0355 - accuracy: 0.6796 - val_loss: 1.0526 - val_accuracy: 0.6813\n",
            "Epoch 26/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0284 - accuracy: 0.6862 - val_loss: 1.0546 - val_accuracy: 0.6717\n",
            "Epoch 27/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0231 - accuracy: 0.6859 - val_loss: 1.0459 - val_accuracy: 0.6763\n",
            "Epoch 28/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0178 - accuracy: 0.6891 - val_loss: 1.0542 - val_accuracy: 0.6623\n",
            "Epoch 29/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0157 - accuracy: 0.6879 - val_loss: 1.0339 - val_accuracy: 0.6897\n",
            "Epoch 30/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 1.0086 - accuracy: 0.6922 - val_loss: 1.0387 - val_accuracy: 0.6763\n",
            "Epoch 31/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 1.0034 - accuracy: 0.6946 - val_loss: 1.0336 - val_accuracy: 0.6623\n",
            "Epoch 32/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9976 - accuracy: 0.6965 - val_loss: 1.0166 - val_accuracy: 0.6870\n",
            "Epoch 33/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9926 - accuracy: 0.6990 - val_loss: 1.0291 - val_accuracy: 0.6880\n",
            "Epoch 34/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9914 - accuracy: 0.6972 - val_loss: 1.0219 - val_accuracy: 0.6883\n",
            "Epoch 35/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9851 - accuracy: 0.7006 - val_loss: 1.0130 - val_accuracy: 0.6900\n",
            "Epoch 36/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9823 - accuracy: 0.7013 - val_loss: 1.0111 - val_accuracy: 0.6717\n",
            "Epoch 37/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9771 - accuracy: 0.7031 - val_loss: 1.0024 - val_accuracy: 0.6910\n",
            "Epoch 38/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9729 - accuracy: 0.7039 - val_loss: 1.0107 - val_accuracy: 0.6680\n",
            "Epoch 39/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9708 - accuracy: 0.7038 - val_loss: 0.9946 - val_accuracy: 0.6983\n",
            "Epoch 40/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.9663 - accuracy: 0.7042 - val_loss: 0.9902 - val_accuracy: 0.6860\n",
            "Epoch 41/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9623 - accuracy: 0.7068 - val_loss: 0.9848 - val_accuracy: 0.6910\n",
            "Epoch 42/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.9596 - accuracy: 0.7066 - val_loss: 0.9806 - val_accuracy: 0.7033\n",
            "Epoch 43/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9537 - accuracy: 0.7094 - val_loss: 0.9864 - val_accuracy: 0.6870\n",
            "Epoch 44/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9512 - accuracy: 0.7104 - val_loss: 0.9788 - val_accuracy: 0.7047\n",
            "Epoch 45/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9474 - accuracy: 0.7121 - val_loss: 0.9787 - val_accuracy: 0.6930\n",
            "Epoch 46/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9461 - accuracy: 0.7104 - val_loss: 0.9911 - val_accuracy: 0.6957\n",
            "Epoch 47/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9425 - accuracy: 0.7123 - val_loss: 0.9674 - val_accuracy: 0.6960\n",
            "Epoch 48/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9416 - accuracy: 0.7130 - val_loss: 0.9769 - val_accuracy: 0.6903\n",
            "Epoch 49/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9381 - accuracy: 0.7124 - val_loss: 0.9736 - val_accuracy: 0.6980\n",
            "Epoch 50/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9323 - accuracy: 0.7160 - val_loss: 0.9588 - val_accuracy: 0.7017\n",
            "Epoch 51/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9304 - accuracy: 0.7155 - val_loss: 0.9590 - val_accuracy: 0.6947\n",
            "Epoch 52/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9276 - accuracy: 0.7171 - val_loss: 0.9589 - val_accuracy: 0.6997\n",
            "Epoch 53/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9261 - accuracy: 0.7172 - val_loss: 0.9552 - val_accuracy: 0.6967\n",
            "Epoch 54/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.9218 - accuracy: 0.7173 - val_loss: 0.9611 - val_accuracy: 0.6967\n",
            "Epoch 55/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9176 - accuracy: 0.7207 - val_loss: 0.9425 - val_accuracy: 0.7103\n",
            "Epoch 56/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9141 - accuracy: 0.7211 - val_loss: 0.9344 - val_accuracy: 0.7143\n",
            "Epoch 57/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9127 - accuracy: 0.7214 - val_loss: 0.9380 - val_accuracy: 0.7153\n",
            "Epoch 58/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9118 - accuracy: 0.7206 - val_loss: 0.9474 - val_accuracy: 0.7033\n",
            "Epoch 59/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9114 - accuracy: 0.7202 - val_loss: 0.9419 - val_accuracy: 0.6993\n",
            "Epoch 60/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9053 - accuracy: 0.7239 - val_loss: 0.9340 - val_accuracy: 0.7203\n",
            "Epoch 61/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.9031 - accuracy: 0.7226 - val_loss: 0.9330 - val_accuracy: 0.7247\n",
            "Epoch 62/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8995 - accuracy: 0.7266 - val_loss: 0.9224 - val_accuracy: 0.7217\n",
            "Epoch 63/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8979 - accuracy: 0.7250 - val_loss: 0.9257 - val_accuracy: 0.7177\n",
            "Epoch 64/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8963 - accuracy: 0.7268 - val_loss: 0.9252 - val_accuracy: 0.7117\n",
            "Epoch 65/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8936 - accuracy: 0.7254 - val_loss: 0.9305 - val_accuracy: 0.7020\n",
            "Epoch 66/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8898 - accuracy: 0.7279 - val_loss: 0.9294 - val_accuracy: 0.7077\n",
            "Epoch 67/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8908 - accuracy: 0.7267 - val_loss: 0.9123 - val_accuracy: 0.7213\n",
            "Epoch 68/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8901 - accuracy: 0.7253 - val_loss: 0.9188 - val_accuracy: 0.7157\n",
            "Epoch 69/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8860 - accuracy: 0.7281 - val_loss: 0.9117 - val_accuracy: 0.7243\n",
            "Epoch 70/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8817 - accuracy: 0.7300 - val_loss: 0.9341 - val_accuracy: 0.7040\n",
            "Epoch 71/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8810 - accuracy: 0.7309 - val_loss: 0.9173 - val_accuracy: 0.7153\n",
            "Epoch 72/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.8797 - accuracy: 0.7300 - val_loss: 0.9102 - val_accuracy: 0.7183\n",
            "Epoch 73/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8775 - accuracy: 0.7313 - val_loss: 0.9457 - val_accuracy: 0.6830\n",
            "Epoch 74/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8734 - accuracy: 0.7323 - val_loss: 0.9012 - val_accuracy: 0.7273\n",
            "Epoch 75/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8723 - accuracy: 0.7336 - val_loss: 0.9036 - val_accuracy: 0.7297\n",
            "Epoch 76/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8718 - accuracy: 0.7334 - val_loss: 0.8934 - val_accuracy: 0.7247\n",
            "Epoch 77/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8685 - accuracy: 0.7347 - val_loss: 0.8919 - val_accuracy: 0.7207\n",
            "Epoch 78/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8659 - accuracy: 0.7354 - val_loss: 0.8936 - val_accuracy: 0.7343\n",
            "Epoch 79/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8658 - accuracy: 0.7346 - val_loss: 0.9038 - val_accuracy: 0.7093\n",
            "Epoch 80/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8652 - accuracy: 0.7350 - val_loss: 0.8963 - val_accuracy: 0.7177\n",
            "Epoch 81/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8624 - accuracy: 0.7343 - val_loss: 0.8935 - val_accuracy: 0.7240\n",
            "Epoch 82/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8620 - accuracy: 0.7355 - val_loss: 0.8952 - val_accuracy: 0.7210\n",
            "Epoch 83/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8617 - accuracy: 0.7342 - val_loss: 0.9287 - val_accuracy: 0.7033\n",
            "Epoch 84/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.8606 - accuracy: 0.7351 - val_loss: 0.8819 - val_accuracy: 0.7297\n",
            "Epoch 85/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8550 - accuracy: 0.7373 - val_loss: 0.8757 - val_accuracy: 0.7333\n",
            "Epoch 86/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8544 - accuracy: 0.7368 - val_loss: 0.8923 - val_accuracy: 0.7240\n",
            "Epoch 87/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8514 - accuracy: 0.7387 - val_loss: 0.8782 - val_accuracy: 0.7287\n",
            "Epoch 88/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8515 - accuracy: 0.7382 - val_loss: 0.8784 - val_accuracy: 0.7337\n",
            "Epoch 89/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8481 - accuracy: 0.7395 - val_loss: 0.8876 - val_accuracy: 0.7210\n",
            "Epoch 90/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8478 - accuracy: 0.7394 - val_loss: 0.8710 - val_accuracy: 0.7323\n",
            "Epoch 91/150\n",
            "65094/65094 [==============================] - 2s 33us/sample - loss: 0.8503 - accuracy: 0.7376 - val_loss: 0.8846 - val_accuracy: 0.7260\n",
            "Epoch 92/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8435 - accuracy: 0.7408 - val_loss: 0.8824 - val_accuracy: 0.7297\n",
            "Epoch 93/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.8432 - accuracy: 0.7404 - val_loss: 0.8801 - val_accuracy: 0.7283\n",
            "Epoch 94/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8420 - accuracy: 0.7410 - val_loss: 0.8816 - val_accuracy: 0.7197\n",
            "Epoch 95/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8435 - accuracy: 0.7396 - val_loss: 0.8647 - val_accuracy: 0.7290\n",
            "Epoch 96/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.8395 - accuracy: 0.7414 - val_loss: 0.8649 - val_accuracy: 0.7280\n",
            "Epoch 97/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8359 - accuracy: 0.7431 - val_loss: 0.8655 - val_accuracy: 0.7283\n",
            "Epoch 98/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8369 - accuracy: 0.7428 - val_loss: 0.8758 - val_accuracy: 0.7287\n",
            "Epoch 99/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.8356 - accuracy: 0.7426 - val_loss: 0.9009 - val_accuracy: 0.7010\n",
            "Epoch 100/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8339 - accuracy: 0.7427 - val_loss: 0.8699 - val_accuracy: 0.7367\n",
            "Epoch 101/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8320 - accuracy: 0.7423 - val_loss: 0.8545 - val_accuracy: 0.7300\n",
            "Epoch 102/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.8305 - accuracy: 0.7431 - val_loss: 0.8488 - val_accuracy: 0.7383\n",
            "Epoch 103/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8299 - accuracy: 0.7444 - val_loss: 0.8580 - val_accuracy: 0.7387\n",
            "Epoch 104/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.8271 - accuracy: 0.7449 - val_loss: 0.8595 - val_accuracy: 0.7387\n",
            "Epoch 105/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8268 - accuracy: 0.7454 - val_loss: 0.8584 - val_accuracy: 0.7320\n",
            "Epoch 106/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8257 - accuracy: 0.7458 - val_loss: 0.8530 - val_accuracy: 0.7353\n",
            "Epoch 107/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8241 - accuracy: 0.7458 - val_loss: 0.8553 - val_accuracy: 0.7390\n",
            "Epoch 108/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8220 - accuracy: 0.7474 - val_loss: 0.8642 - val_accuracy: 0.7200\n",
            "Epoch 109/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8188 - accuracy: 0.7484 - val_loss: 0.8539 - val_accuracy: 0.7270\n",
            "Epoch 110/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8173 - accuracy: 0.7491 - val_loss: 0.8458 - val_accuracy: 0.7393\n",
            "Epoch 111/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8212 - accuracy: 0.7468 - val_loss: 0.8500 - val_accuracy: 0.7413\n",
            "Epoch 112/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8181 - accuracy: 0.7473 - val_loss: 0.8497 - val_accuracy: 0.7317\n",
            "Epoch 113/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8191 - accuracy: 0.7463 - val_loss: 0.8523 - val_accuracy: 0.7247\n",
            "Epoch 114/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.8155 - accuracy: 0.7491 - val_loss: 0.8509 - val_accuracy: 0.7267\n",
            "Epoch 115/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.8144 - accuracy: 0.7477 - val_loss: 0.8398 - val_accuracy: 0.7330\n",
            "Epoch 116/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.8140 - accuracy: 0.7503 - val_loss: 0.8580 - val_accuracy: 0.7300\n",
            "Epoch 117/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8170 - accuracy: 0.7469 - val_loss: 0.8453 - val_accuracy: 0.7337\n",
            "Epoch 118/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8115 - accuracy: 0.7499 - val_loss: 0.8461 - val_accuracy: 0.7327\n",
            "Epoch 119/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8104 - accuracy: 0.7505 - val_loss: 0.8549 - val_accuracy: 0.7333\n",
            "Epoch 120/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8104 - accuracy: 0.7490 - val_loss: 0.8844 - val_accuracy: 0.7067\n",
            "Epoch 121/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.8060 - accuracy: 0.7530 - val_loss: 0.8483 - val_accuracy: 0.7347\n",
            "Epoch 122/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8065 - accuracy: 0.7513 - val_loss: 0.8338 - val_accuracy: 0.7440\n",
            "Epoch 123/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8092 - accuracy: 0.7495 - val_loss: 0.8420 - val_accuracy: 0.7423\n",
            "Epoch 124/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.8051 - accuracy: 0.7513 - val_loss: 0.8290 - val_accuracy: 0.7337\n",
            "Epoch 125/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8019 - accuracy: 0.7534 - val_loss: 0.8370 - val_accuracy: 0.7353\n",
            "Epoch 126/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.8023 - accuracy: 0.7524 - val_loss: 0.8322 - val_accuracy: 0.7333\n",
            "Epoch 127/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.7974 - accuracy: 0.7541 - val_loss: 0.8285 - val_accuracy: 0.7447\n",
            "Epoch 128/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.7997 - accuracy: 0.7530 - val_loss: 0.8316 - val_accuracy: 0.7413\n",
            "Epoch 129/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.8007 - accuracy: 0.7526 - val_loss: 0.8327 - val_accuracy: 0.7327\n",
            "Epoch 130/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.7998 - accuracy: 0.7523 - val_loss: 0.8260 - val_accuracy: 0.7460\n",
            "Epoch 131/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.7971 - accuracy: 0.7536 - val_loss: 0.8385 - val_accuracy: 0.7333\n",
            "Epoch 132/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.7983 - accuracy: 0.7532 - val_loss: 0.8306 - val_accuracy: 0.7347\n",
            "Epoch 133/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.7952 - accuracy: 0.7541 - val_loss: 0.8243 - val_accuracy: 0.7380\n",
            "Epoch 134/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.7937 - accuracy: 0.7554 - val_loss: 0.8496 - val_accuracy: 0.7303\n",
            "Epoch 135/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.7951 - accuracy: 0.7542 - val_loss: 0.8200 - val_accuracy: 0.7430\n",
            "Epoch 136/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.7923 - accuracy: 0.7556 - val_loss: 0.8447 - val_accuracy: 0.7377\n",
            "Epoch 137/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.7944 - accuracy: 0.7527 - val_loss: 0.8184 - val_accuracy: 0.7400\n",
            "Epoch 138/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.7918 - accuracy: 0.7550 - val_loss: 0.8255 - val_accuracy: 0.7350\n",
            "Epoch 139/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.7924 - accuracy: 0.7544 - val_loss: 0.8219 - val_accuracy: 0.7363\n",
            "Epoch 140/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.7883 - accuracy: 0.7564 - val_loss: 0.8263 - val_accuracy: 0.7340\n",
            "Epoch 141/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.7890 - accuracy: 0.7563 - val_loss: 0.8175 - val_accuracy: 0.7470\n",
            "Epoch 142/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.7890 - accuracy: 0.7550 - val_loss: 0.8249 - val_accuracy: 0.7317\n",
            "Epoch 143/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.7866 - accuracy: 0.7572 - val_loss: 0.8180 - val_accuracy: 0.7403\n",
            "Epoch 144/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.7865 - accuracy: 0.7566 - val_loss: 0.8164 - val_accuracy: 0.7517\n",
            "Epoch 145/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.7871 - accuracy: 0.7562 - val_loss: 0.8180 - val_accuracy: 0.7420\n",
            "Epoch 146/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.7831 - accuracy: 0.7572 - val_loss: 0.8116 - val_accuracy: 0.7410\n",
            "Epoch 147/150\n",
            "65094/65094 [==============================] - 2s 31us/sample - loss: 0.7833 - accuracy: 0.7576 - val_loss: 0.8289 - val_accuracy: 0.7443\n",
            "Epoch 148/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.7817 - accuracy: 0.7581 - val_loss: 0.8361 - val_accuracy: 0.7317\n",
            "Epoch 149/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.7839 - accuracy: 0.7569 - val_loss: 0.8120 - val_accuracy: 0.7493\n",
            "Epoch 150/150\n",
            "65094/65094 [==============================] - 2s 32us/sample - loss: 0.7815 - accuracy: 0.7572 - val_loss: 0.8346 - val_accuracy: 0.7243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r8_mvDjYL3CX",
        "colab_type": "code",
        "outputId": "f1b02329-bfe9-4117-c130-48eb23b4eba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_label)\n",
        "print(results)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7567/7567 [==============================] - 1s 105us/sample - loss: 0.8068 - accuracy: 0.7371\n",
            "[0.8067786961427623, 0.73714817]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VaIioR7EPfig",
        "colab_type": "code",
        "outputId": "3e446dd4-121b-487c-a27c-acad9575edfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "data_index   = 12\n",
        "data_words   = \" \".join(test_data_words[data_index])\n",
        "data_indexes = test_data[data_index]\n",
        "print(data_words)\n",
        "\n",
        "predicted = model.predict([[data_indexes]])\n",
        "print(encoder.classes_[np.argmax(predicted)])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "спортын төв ордонд өнөөдөр азийн оюутны аварга шалгаруулах эмэгтэй волейболчдын хоёр дахь удаагийн тэмцээний талаар мэдээлэл хийлээ анхны тэмцээн онд тайландын бангконг хотноо болж хоёрдугаар тэмцээнийг азийн оюутны спортын холбооноос аосх олгосон эрхийн дагуу оны дөрөвдүгээр сарын ны өдрүүдэд монгол улсын нийслэл улаанбаатар хотноо зохион байгуулах тэмцээний эрхийг монгол улс оны тавдугаар сарын хуралдсан аосхны гүйцэтгэх хорооны хурлаар хоёр оронтой өрсөлдөн авчээ уг тэмцээнийг монгол улсад авах талаар мосхолбоо оноос санаачлага гарган хөөцөлдөж эхэлсэн тэмцээний эрхийг авахад муын засгийн газрын санхүүгийн дэмжлэг мэргэжлийн холбоодын ажлын туршлага манай улсын олон улсын нэр хүнд ихээхэн тус хүргэжээ зохион байгуулах хороог с ламбаа удирдаж тэмцээний зохион байгуулах хороог збх эрүүл мэндийн сайдын оны тоот тушаалаар батлаж даргаар уихын гишүүн монголын волейболын холбооны мвх хүндэт ерөнхийлөгч сламбаа ажиллаж збхны орлогч даргаар згхагентлагбтсгын дарга чнаранбаатар збхны нарийн бичгийн даргаар монголын оюутны спортын холбооны мосх ерөнхий нарийн бичгийн дарга джаргалсайхан збхны гишүүдэд бсшуяны төрийн нарийн бичгийн дарга ддалайжаргал нийслэлийн здтгазрын дарга цболдсайхан сяны газрын дарга дбатжаргал гхяамны консулын газрын дарга дганхуяг бсшуяны мэргэжлийн боловсролын газрын дарга мбаасанжав гихалбаны дарга дмөрөн мосхны ерөнхийлөгч оуосхны ерөнхий санхүүч дбаясгалан муисийн ректор стөмөрочир мубисийн ректор бжадамба залуу монгол корпорацийн ерөнхийлөгч мсономпил мохны ерөнхий нарийн бичгийн дарга нбямбагэрэл мвхолбооны ерөнхий нарий бичгийн дарга цбатэнх миат хкийн маркетинг борлуулатын хэлтсийн дарга тмэндсайхан боловсрол суваг телевизийн ерөнхий захирал аамундра нар сонгогдон ажиллаж тэмцээнийг үнэ төлбөргүй үзүүлнэ волейболын болон оюутны спортыг сурталчилах дэлгэрүүлэх үүднээс тэмцээнийг үнэ төлбөргүй үзүүлэхээр збхорооны анхдугаар хурлаас шийдвэрлэсэн нийслэлийн иргэдийг тэмцээнийг өргөнөөр үзэхийг здтгазраас уриалсан тэмцээнийг зөвхөн улаанбаатар хотын иргэд бус аймгаас волейболын спортыг сонирхон хөгжөөн дэмжигч үзэгч волейболын спортын мэргэжилтэн багш нар секцэнд хичээллэгч хүүхдүүд зохион байгуулалтай ирэхээр ялангуяа тэмцээн болох газартай хамгийн ойрхон хануул дүүргийн здтгазар дүүргийнхээ ард иргэд хөдөлмөрчид сургуулийн сурагчид оюутнууд цэргийн албан хаагчид буянтухаа орчимын албан байгууллага хамт олныг идэвхтэй оролцуулах арга хэмжээ авч эхлэжээ олон зуун оюутнууд тэмцээн үзэх боллоо тэмцээний өдрүүдэд нийслэлээс буянтухаагийн спортын ордонг чиглэсэн хүмүүсийн цуваа ихсэх төлөвтэй учир нийслэлд үйл ажиллагаа явуулж байгаа орчим идсийн оюутнууд тэмцээнийг анги сургууль хамт олноороо үзэх сонирхолтой байгаагаа монголын оюутны холбоо биеийн тамирын тэнхимдээ хүсчээ үүний дагуу бсшуяам мох монголын оюутны спортын холбоо мосх ноос тэмцээнийг өдөр бүр гаруй сургуулийн орчим оюутнууд нэгдсэн хуваарийн дагуу үзэх хуваарийг бсшуяны төрийн нарийн бичгийн дарга зохион байгуулах үндэсний хороо збх ны гишүүн ддалайжаргал батлан сургуулиудад албан тоотоор хүргүүлжээ мосхд тэмцээнийг үзэхээр олон арван сургуулиуд оюутны тоогоо өгч бүртгүүлж суудлын хувиарлалтанд орж байгаа ажээ ялангуяа биеийн тамирын мэргэжлийн дээд сургуулийн оюутнууд дадлага хичээлээ тэмцээний үеэр хийхээр хичээлийн хувиараа зохицуулсан нийслэлийн засаг дарга оюутнуудад туслав улаанбаатар хотноо болдог оюутны олон улс тив дэлхийн тэмцээн бүрт нийслэлийн засаг дарга гмөнхбаяр ихээхэн туслалцаа үзүүлэн оюутан залуусаа байнга дэмжин оролцдог ажээ тэрээр тус тэмцээнд оролцохоор бэлтгэж байгаа монголын оюутны шигшээ багийн тамирчидын хоногийн бэлтгэл сургалтын зардлыг хариуцан гаргасан хөрөнгө санхүүгийн хүндрэлтэй байгаа үеэд тэмцээнд бэлтгэж байгаа оюутан тамирчидаа цагаа олж хэрэгцээтэй үеэд дэмжлээ мосхолбоо монголын волейболын холбоо мвх тамирчидынхаа өмнөөс талархал илэрхийлжээ монголын баг тамирчид эрдэнэт хотод оны сарын өдрөөс эхлэн хоногийн бэлтгэл хийснийхээ дараа ийнхүү нийслэлийн засаг даргын туслалцаатайгаар гадаадын тамирчидтай хамт байрлах цэцэг зочид буудалдаа орж бэлтгэл сургуулиалтаа үргэлжүүлэх боломжтой нздтгазраас баг\n",
            "спорт\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
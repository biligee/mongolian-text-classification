{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mongolian text classification #03, Multiple 1D Convolution layers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "muNP8k9fqaJb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mongolian text classification series #01\n",
        "\n",
        "In this notebook I'm gonna try to classify cyrillic mongolian texts with 1D convnet. In this case, architecture from [official Keras documention](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html) will be replicated and also functional API used.\n",
        "\n",
        "Eduge dataset provided by Bolorsoft LLC\n",
        "\n",
        "Author : Sharavsambuu Gunchinish (sharavsambuu@gmail.com)\n",
        "\n",
        "Github: https://github.com/sharavsambuu/mongolian-text-classification \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "iY9jwdg6qT8M",
        "colab_type": "code",
        "outputId": "7f7974c2-abe9-437c-b08b-7b5b8d3426da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "!pip install gensim\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.2.1)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.130)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.130 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.130)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.0)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "smJeJfoo4qcu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[More info about creation of eduge dataset pickles](https://github.com/sharavsambuu/mongolian-text-classification/blob/master/preprocess_dataset/preprocess_eduge.ipynb) preprocessing eats a lot of CPU cycle so it's good idea to cook it before using colab."
      ]
    },
    {
      "metadata": {
        "id": "CDayX_Yx3REh",
        "colab_type": "code",
        "outputId": "a92dc579-268e-4b62-bb3b-59dc60bfe8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "import sys\n",
        "\n",
        "def download_from_google_drive(file_id, file_name):\n",
        "  !rm -f ./cookie\n",
        "  !curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=$file_id\" > /dev/null\n",
        "  confirm_text = !awk '/download/ {print $NF}' ./cookie\n",
        "  confirm_text = confirm_text[0]\n",
        "  !curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=$confirm_text&id=$file_id\" -o $file_name\n",
        "  \n",
        "# download eduge pickles\n",
        "file_path = 'eduge_pickles'\n",
        "if not exists(file_path):\n",
        "  download_from_google_drive('1vjJ9YgIe8o0ErhbN0lH1XqPv3KFP8acv', '%s.rar' % file_path)\n",
        "  rar_file = file_path+\".rar\"\n",
        "  !unrar x $rar_file"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   388    0   388    0     0   7461      0 --:--:-- --:--:-- --:--:--  7461\n",
            "100  106M    0  106M    0     0   112M      0 --:--:-- --:--:-- --:--:--  150M\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from eduge_pickles.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file word_index.pickle\n",
            "9178153 bytes, modified on 2019-04-13 01:44\n",
            "with a new one\n",
            "9178153 bytes, modified on 2019-04-13 01:44\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit q\n",
            "\n",
            "Program aborted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pPHJcnfi4Rzg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('word_index.pickle', 'rb') as handle:\n",
        "  word_index = pickle.load(handle)\n",
        "    \n",
        "with open('reversed_word_index.pickle', 'rb') as handle:\n",
        "  reversed_word_index = pickle.load(handle)\n",
        "  \n",
        "with open('eduge_stopwords_removed.pickle', 'rb') as handle:\n",
        "  eduge_ds = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ASRW7ISNnbM-",
        "colab_type": "code",
        "outputId": "5ea1f89b-d363-4a9c-b999-f6de0cac454d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# facebook trained word2vec on both commoncrawl and wikipedia. So this model should contain enough representation about our mongolian words.\n",
        "mongolian_word2vec_download=\"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.mn.300.bin.gz\"\n",
        "if not exists(\"cc.mn.300.bin.gz\"):\n",
        "  !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.mn.300.bin.gz\n",
        "if exists('cc.mn.300.bin.gz'):\n",
        "  !gunzip cc.mn.300.bin.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: cc.mn.300.bin already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BqGAauUZpnFz",
        "colab_type": "code",
        "outputId": "d1ffdeb6-c565-4f6e-835b-ef888fb106eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.wrappers import FastText\n",
        "\n",
        "word2vec_model = FastText.load_fasttext_format('cc.mn.300.bin')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0413 23:29:51.869181 140649000748928 ssh.py:33] paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
            "W0413 23:29:52.127143 140649000748928 word2vec.py:573] Slow version of gensim.models.deprecated.word2vec is being used\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kkc1iiqJp-CJ",
        "colab_type": "code",
        "outputId": "fc0a7176-73a0-44f7-c16a-ccb0dee76d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "print(word2vec_model.most_similar('монгол'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Монгол', 0.6342526078224182), ('монголын', 0.6047513484954834), ('хятад', 0.5558866858482361), ('Монголын', 0.5087883472442627), ('судлалаараа', 0.48851606249809265), ('манай', 0.4853793680667877), ('уйгаржин', 0.4725492596626282), ('угсаатангууд', 0.47093287110328674), ('орос', 0.46463483572006226), ('худам', 0.4609120190143585)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oF6vB3Qnq08I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# preparing embedding matrix\n",
        "import numpy as np\n",
        "\n",
        "words_not_found = []\n",
        "embed_dim       = 300\n",
        "embedding_matrix = np.random.uniform(-1, 1, (len(word_index), embed_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i<4:\n",
        "    continue\n",
        "  try:\n",
        "    embedding_vector = word2vec_model[word]\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "  except:\n",
        "    words_not_found.append(word)\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQAaXWIgsxm9",
        "colab_type": "code",
        "outputId": "98b1bd32-6e6a-44e6-ad87-5c77748ed32e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(embedding_matrix.shape)\n",
        "#print(embedding_matrix[5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(370794, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XFxd1QGR65VV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512\n",
        "\n",
        "import itertools\n",
        "\n",
        "for item in eduge_ds:\n",
        "  item[0] = list(itertools.chain(*item[0]))[:MAX_LEN]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U8PTeX0WCbhR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(eduge_ds, test_size=0.1, random_state=999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8mgMCFcgDHH4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_words  = [i[0] for i in train]\n",
        "train_label_words = [i[1] for i in train]\n",
        "test_data_words   = [i[0] for i in test ]\n",
        "test_label_words  = [i[1] for i in test ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rrXC7UiuFkCH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def encode_news(text):\n",
        "    return [word_index.get(i, 2) for i in text]\n",
        "  \n",
        "train_data = [encode_news(sent) for sent in train_data_words]\n",
        "test_data  = [encode_news(sent) for sent in test_data_words ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FV-h_avPEzM1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=MAX_LEN)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDVqmPqxIMid",
        "colab_type": "code",
        "outputId": "ecbdacf2-593d-4b82-bdf6-3584d56fa789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "labels = list(set(test_label_words))\n",
        "labels"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['эрүүл мэнд',\n",
              " 'эдийн засаг',\n",
              " 'хууль',\n",
              " 'улс төр',\n",
              " 'спорт',\n",
              " 'боловсрол',\n",
              " 'байгал орчин',\n",
              " 'урлаг соёл',\n",
              " 'технологи']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "PBKj3GQqJq29",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder     = LabelBinarizer()\n",
        "train_label = transfomed_label = encoder.fit_transform(train_label_words)\n",
        "test_label  = transfomed_label = encoder.fit_transform(test_label_words )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DPq45PN5HZ15",
        "colab_type": "code",
        "outputId": "e1a19379-f112-40da-f9b8-0e562ea3f7da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_index)\n",
        "\n",
        "sequence_input     = keras.layers.Input(shape=(MAX_LEN,), dtype='int32')\n",
        "embedded_sequences = keras.layers.Embedding(\n",
        "    vocab_size, \n",
        "    embed_dim , \n",
        "    weights=[embedding_matrix], \n",
        "    input_length=MAX_LEN, \n",
        "    trainable=False)(sequence_input)\n",
        "x = keras.layers.Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
        "x = keras.layers.MaxPooling1D(5)(x)\n",
        "x = keras.layers.Conv1D(128, 5, activation='relu')(x)\n",
        "x = keras.layers.MaxPooling1D(5)(x)\n",
        "x = keras.layers.Conv1D(128, 5, activation='relu')(x)\n",
        "x = keras.layers.MaxPooling1D(15)(x) # global max pooling\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(128, activation='relu')(x)\n",
        "preds = keras.layers.Dense(len(labels), activation='softmax')(x)\n",
        "\n",
        "model = keras.models.Model(sequence_input, preds)\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 512)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 512, 300)          111238200 \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 508, 128)          192128    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 101, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 97, 128)           82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 15, 128)           82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 9)                 1161      \n",
            "=================================================================\n",
            "Total params: 111,612,097\n",
            "Trainable params: 373,897\n",
            "Non-trainable params: 111,238,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cAgP1KlqHu2F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPw8roFQKrHm",
        "colab_type": "code",
        "outputId": "55985963-7017-4a96-b9b9-7c63522515c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(train_data), len(train_label))\n",
        "print(len(test_data ), len(test_label) )\n",
        "\n",
        "partial_index = 3000\n",
        "\n",
        "x_val = train_data[:partial_index]\n",
        "partial_x_train = train_data[partial_index:]\n",
        "\n",
        "y_val = train_label[:partial_index]\n",
        "partial_y_train = train_label[partial_index:]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68094 68094\n",
            "7567 7567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iSTB4--RKacs",
        "colab_type": "code",
        "outputId": "f17b0e17-4912-40eb-bfba-ad1f27970373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3141
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 150\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs  ,\n",
        "                    batch_size=512 ,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 65094 samples, validate on 3000 samples\n",
            "Epoch 1/150\n",
            "65094/65094 [==============================] - 29s 451us/sample - loss: 1.5893 - accuracy: 0.4209 - val_loss: 1.2512 - val_accuracy: 0.5380\n",
            "Epoch 2/150\n",
            "65094/65094 [==============================] - 24s 368us/sample - loss: 1.0078 - accuracy: 0.6598 - val_loss: 0.9924 - val_accuracy: 0.6577\n",
            "Epoch 3/150\n",
            "65094/65094 [==============================] - 24s 366us/sample - loss: 0.7461 - accuracy: 0.7561 - val_loss: 0.8013 - val_accuracy: 0.7407\n",
            "Epoch 4/150\n",
            "65094/65094 [==============================] - 24s 366us/sample - loss: 0.5728 - accuracy: 0.8187 - val_loss: 0.7278 - val_accuracy: 0.7653\n",
            "Epoch 5/150\n",
            "65094/65094 [==============================] - 24s 365us/sample - loss: 0.4723 - accuracy: 0.8512 - val_loss: 0.7614 - val_accuracy: 0.7557\n",
            "Epoch 6/150\n",
            "65094/65094 [==============================] - 24s 366us/sample - loss: 0.4049 - accuracy: 0.8728 - val_loss: 0.5384 - val_accuracy: 0.8317\n",
            "Epoch 7/150\n",
            "65094/65094 [==============================] - 24s 365us/sample - loss: 0.3475 - accuracy: 0.8902 - val_loss: 0.4653 - val_accuracy: 0.8587\n",
            "Epoch 8/150\n",
            "65094/65094 [==============================] - 24s 364us/sample - loss: 0.3034 - accuracy: 0.9035 - val_loss: 0.4753 - val_accuracy: 0.8610\n",
            "Epoch 9/150\n",
            "65094/65094 [==============================] - 24s 365us/sample - loss: 0.2626 - accuracy: 0.9154 - val_loss: 0.4949 - val_accuracy: 0.8543\n",
            "Epoch 10/150\n",
            "65094/65094 [==============================] - 24s 364us/sample - loss: 0.2279 - accuracy: 0.9272 - val_loss: 0.8323 - val_accuracy: 0.7790\n",
            "Epoch 11/150\n",
            "65094/65094 [==============================] - 24s 364us/sample - loss: 0.1947 - accuracy: 0.9379 - val_loss: 0.6615 - val_accuracy: 0.8217\n",
            "Epoch 12/150\n",
            "65094/65094 [==============================] - 24s 364us/sample - loss: 0.1739 - accuracy: 0.9434 - val_loss: 0.5418 - val_accuracy: 0.8560\n",
            "Epoch 13/150\n",
            "65094/65094 [==============================] - 24s 365us/sample - loss: 0.1506 - accuracy: 0.9513 - val_loss: 0.6424 - val_accuracy: 0.8370\n",
            "Epoch 14/150\n",
            "65094/65094 [==============================] - 24s 364us/sample - loss: 0.1321 - accuracy: 0.9587 - val_loss: 0.6743 - val_accuracy: 0.8297\n",
            "Epoch 15/150\n",
            "65094/65094 [==============================] - 24s 364us/sample - loss: 0.1225 - accuracy: 0.9615 - val_loss: 0.7838 - val_accuracy: 0.8197\n",
            "Epoch 16/150\n",
            "65094/65094 [==============================] - 24s 364us/sample - loss: 0.1019 - accuracy: 0.9681 - val_loss: 0.6871 - val_accuracy: 0.8377\n",
            "Epoch 17/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0951 - accuracy: 0.9702 - val_loss: 0.9579 - val_accuracy: 0.7910\n",
            "Epoch 18/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0892 - accuracy: 0.9732 - val_loss: 0.7295 - val_accuracy: 0.8407\n",
            "Epoch 19/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0809 - accuracy: 0.9758 - val_loss: 0.9078 - val_accuracy: 0.8130\n",
            "Epoch 20/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0742 - accuracy: 0.9783 - val_loss: 1.2826 - val_accuracy: 0.7717\n",
            "Epoch 21/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0764 - accuracy: 0.9788 - val_loss: 0.8790 - val_accuracy: 0.8317\n",
            "Epoch 22/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0653 - accuracy: 0.9812 - val_loss: 0.7506 - val_accuracy: 0.8400\n",
            "Epoch 23/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0633 - accuracy: 0.9817 - val_loss: 1.0626 - val_accuracy: 0.8040\n",
            "Epoch 24/150\n",
            "65094/65094 [==============================] - 24s 364us/sample - loss: 0.0622 - accuracy: 0.9819 - val_loss: 0.7558 - val_accuracy: 0.8533\n",
            "Epoch 25/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0602 - accuracy: 0.9839 - val_loss: 0.9062 - val_accuracy: 0.8347\n",
            "Epoch 26/150\n",
            "65094/65094 [==============================] - 24s 364us/sample - loss: 0.0548 - accuracy: 0.9845 - val_loss: 0.7949 - val_accuracy: 0.8493\n",
            "Epoch 27/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0547 - accuracy: 0.9847 - val_loss: 0.8777 - val_accuracy: 0.8387\n",
            "Epoch 28/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0538 - accuracy: 0.9847 - val_loss: 0.8139 - val_accuracy: 0.8517\n",
            "Epoch 29/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0537 - accuracy: 0.9848 - val_loss: 0.8294 - val_accuracy: 0.8460\n",
            "Epoch 30/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0452 - accuracy: 0.9870 - val_loss: 0.9613 - val_accuracy: 0.8313\n",
            "Epoch 31/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0519 - accuracy: 0.9849 - val_loss: 0.8400 - val_accuracy: 0.8493\n",
            "Epoch 32/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0425 - accuracy: 0.9874 - val_loss: 0.7947 - val_accuracy: 0.8540\n",
            "Epoch 33/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0423 - accuracy: 0.9873 - val_loss: 0.8694 - val_accuracy: 0.8513\n",
            "Epoch 34/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0363 - accuracy: 0.9887 - val_loss: 0.9221 - val_accuracy: 0.8377\n",
            "Epoch 35/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.8841 - val_accuracy: 0.8463\n",
            "Epoch 36/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0379 - accuracy: 0.9881 - val_loss: 1.2707 - val_accuracy: 0.8003\n",
            "Epoch 37/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0377 - accuracy: 0.9879 - val_loss: 1.1263 - val_accuracy: 0.8367\n",
            "Epoch 38/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0353 - accuracy: 0.9887 - val_loss: 1.0913 - val_accuracy: 0.8287\n",
            "Epoch 39/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0363 - accuracy: 0.9882 - val_loss: 1.1752 - val_accuracy: 0.8033\n",
            "Epoch 40/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0361 - accuracy: 0.9884 - val_loss: 1.0113 - val_accuracy: 0.8413\n",
            "Epoch 41/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.9572 - val_accuracy: 0.8583\n",
            "Epoch 42/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0378 - accuracy: 0.9886 - val_loss: 0.9180 - val_accuracy: 0.8560\n",
            "Epoch 43/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0309 - accuracy: 0.9900 - val_loss: 1.0604 - val_accuracy: 0.8257\n",
            "Epoch 44/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0317 - accuracy: 0.9894 - val_loss: 0.9254 - val_accuracy: 0.8510\n",
            "Epoch 45/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0262 - accuracy: 0.9905 - val_loss: 1.0133 - val_accuracy: 0.8533\n",
            "Epoch 46/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0302 - accuracy: 0.9898 - val_loss: 0.9832 - val_accuracy: 0.8610\n",
            "Epoch 47/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0295 - accuracy: 0.9896 - val_loss: 1.0226 - val_accuracy: 0.8533\n",
            "Epoch 48/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0296 - accuracy: 0.9899 - val_loss: 1.0043 - val_accuracy: 0.8537\n",
            "Epoch 49/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0292 - accuracy: 0.9897 - val_loss: 1.0569 - val_accuracy: 0.8560\n",
            "Epoch 50/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0268 - accuracy: 0.9897 - val_loss: 1.1791 - val_accuracy: 0.8377\n",
            "Epoch 51/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0253 - accuracy: 0.9912 - val_loss: 1.1057 - val_accuracy: 0.8553\n",
            "Epoch 52/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0278 - accuracy: 0.9901 - val_loss: 1.1723 - val_accuracy: 0.8523\n",
            "Epoch 53/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0272 - accuracy: 0.9905 - val_loss: 1.4094 - val_accuracy: 0.8303\n",
            "Epoch 54/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0252 - accuracy: 0.9907 - val_loss: 1.0860 - val_accuracy: 0.8450\n",
            "Epoch 55/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0235 - accuracy: 0.9912 - val_loss: 1.2556 - val_accuracy: 0.8387\n",
            "Epoch 56/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0254 - accuracy: 0.9905 - val_loss: 1.1428 - val_accuracy: 0.8403\n",
            "Epoch 57/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0233 - accuracy: 0.9911 - val_loss: 1.2151 - val_accuracy: 0.8540\n",
            "Epoch 58/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0248 - accuracy: 0.9912 - val_loss: 2.0298 - val_accuracy: 0.8000\n",
            "Epoch 59/150\n",
            "65094/65094 [==============================] - 24s 362us/sample - loss: 0.0272 - accuracy: 0.9906 - val_loss: 1.2076 - val_accuracy: 0.8327\n",
            "Epoch 60/150\n",
            "65094/65094 [==============================] - 24s 363us/sample - loss: 0.0220 - accuracy: 0.9918 - val_loss: 1.3261 - val_accuracy: 0.8470\n",
            "Epoch 61/150\n",
            "57344/65094 [=========================>....] - ETA: 2s - loss: 0.0261 - accuracy: 0.9905"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f63bf567fa9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    871\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "r8_mvDjYL3CX",
        "colab_type": "code",
        "outputId": "94c969ae-8ac2-48cb-9b7a-51b7bf1e4f93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_label)\n",
        "print(results)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7567/7567 [==============================] - 3s 332us/sample - loss: 1.1013 - accuracy: 0.8515\n",
            "[1.101346154871147, 0.8514603]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VaIioR7EPfig",
        "colab_type": "code",
        "outputId": "68240caa-31fb-49bd-c88e-f6bbbe7707ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "data_index   = 12\n",
        "data_words   = \" \".join(test_data_words[data_index])\n",
        "data_indexes = test_data[data_index]\n",
        "print(data_words)\n",
        "\n",
        "predicted = model.predict([[data_indexes]])\n",
        "print(encoder.classes_[np.argmax(predicted)])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "спортын төв ордонд өнөөдөр азийн оюутны аварга шалгаруулах эмэгтэй волейболчдын хоёр дахь удаагийн тэмцээний талаар мэдээлэл хийлээ анхны тэмцээн онд тайландын бангконг хотноо болж хоёрдугаар тэмцээнийг азийн оюутны спортын холбооноос аосх олгосон эрхийн дагуу оны дөрөвдүгээр сарын ны өдрүүдэд монгол улсын нийслэл улаанбаатар хотноо зохион байгуулах тэмцээний эрхийг монгол улс оны тавдугаар сарын хуралдсан аосхны гүйцэтгэх хорооны хурлаар хоёр оронтой өрсөлдөн авчээ уг тэмцээнийг монгол улсад авах талаар мосхолбоо оноос санаачлага гарган хөөцөлдөж эхэлсэн тэмцээний эрхийг авахад муын засгийн газрын санхүүгийн дэмжлэг мэргэжлийн холбоодын ажлын туршлага манай улсын олон улсын нэр хүнд ихээхэн тус хүргэжээ зохион байгуулах хороог с ламбаа удирдаж тэмцээний зохион байгуулах хороог збх эрүүл мэндийн сайдын оны тоот тушаалаар батлаж даргаар уихын гишүүн монголын волейболын холбооны мвх хүндэт ерөнхийлөгч сламбаа ажиллаж збхны орлогч даргаар згхагентлагбтсгын дарга чнаранбаатар збхны нарийн бичгийн даргаар монголын оюутны спортын холбооны мосх ерөнхий нарийн бичгийн дарга джаргалсайхан збхны гишүүдэд бсшуяны төрийн нарийн бичгийн дарга ддалайжаргал нийслэлийн здтгазрын дарга цболдсайхан сяны газрын дарга дбатжаргал гхяамны консулын газрын дарга дганхуяг бсшуяны мэргэжлийн боловсролын газрын дарга мбаасанжав гихалбаны дарга дмөрөн мосхны ерөнхийлөгч оуосхны ерөнхий санхүүч дбаясгалан муисийн ректор стөмөрочир мубисийн ректор бжадамба залуу монгол корпорацийн ерөнхийлөгч мсономпил мохны ерөнхий нарийн бичгийн дарга нбямбагэрэл мвхолбооны ерөнхий нарий бичгийн дарга цбатэнх миат хкийн маркетинг борлуулатын хэлтсийн дарга тмэндсайхан боловсрол суваг телевизийн ерөнхий захирал аамундра нар сонгогдон ажиллаж тэмцээнийг үнэ төлбөргүй үзүүлнэ волейболын болон оюутны спортыг сурталчилах дэлгэрүүлэх үүднээс тэмцээнийг үнэ төлбөргүй үзүүлэхээр збхорооны анхдугаар хурлаас шийдвэрлэсэн нийслэлийн иргэдийг тэмцээнийг өргөнөөр үзэхийг здтгазраас уриалсан тэмцээнийг зөвхөн улаанбаатар хотын иргэд бус аймгаас волейболын спортыг сонирхон хөгжөөн дэмжигч үзэгч волейболын спортын мэргэжилтэн багш нар секцэнд хичээллэгч хүүхдүүд зохион байгуулалтай ирэхээр ялангуяа тэмцээн болох газартай хамгийн ойрхон хануул дүүргийн здтгазар дүүргийнхээ ард иргэд хөдөлмөрчид сургуулийн сурагчид оюутнууд цэргийн албан хаагчид буянтухаа орчимын албан байгууллага хамт олныг идэвхтэй оролцуулах арга хэмжээ авч эхлэжээ олон зуун оюутнууд тэмцээн үзэх боллоо тэмцээний өдрүүдэд нийслэлээс буянтухаагийн спортын ордонг чиглэсэн хүмүүсийн цуваа ихсэх төлөвтэй учир нийслэлд үйл ажиллагаа явуулж байгаа орчим идсийн оюутнууд тэмцээнийг анги сургууль хамт олноороо үзэх сонирхолтой байгаагаа монголын оюутны холбоо биеийн тамирын тэнхимдээ хүсчээ үүний дагуу бсшуяам мох монголын оюутны спортын холбоо мосх ноос тэмцээнийг өдөр бүр гаруй сургуулийн орчим оюутнууд нэгдсэн хуваарийн дагуу үзэх хуваарийг бсшуяны төрийн нарийн бичгийн дарга зохион байгуулах үндэсний хороо збх ны гишүүн ддалайжаргал батлан сургуулиудад албан тоотоор хүргүүлжээ мосхд тэмцээнийг үзэхээр олон арван сургуулиуд оюутны тоогоо өгч бүртгүүлж суудлын хувиарлалтанд орж байгаа ажээ ялангуяа биеийн тамирын мэргэжлийн дээд сургуулийн оюутнууд дадлага хичээлээ тэмцээний үеэр хийхээр хичээлийн хувиараа зохицуулсан нийслэлийн засаг дарга оюутнуудад туслав улаанбаатар хотноо болдог оюутны олон улс тив дэлхийн тэмцээн бүрт нийслэлийн засаг дарга гмөнхбаяр ихээхэн туслалцаа үзүүлэн оюутан залуусаа байнга дэмжин оролцдог ажээ тэрээр тус тэмцээнд оролцохоор бэлтгэж байгаа монголын оюутны шигшээ багийн тамирчидын хоногийн бэлтгэл сургалтын зардлыг хариуцан гаргасан хөрөнгө санхүүгийн хүндрэлтэй байгаа үеэд тэмцээнд бэлтгэж байгаа оюутан тамирчидаа цагаа олж хэрэгцээтэй үеэд дэмжлээ мосхолбоо монголын волейболын холбоо мвх тамирчидынхаа өмнөөс талархал илэрхийлжээ монголын баг тамирчид эрдэнэт хотод оны сарын өдрөөс эхлэн хоногийн бэлтгэл хийснийхээ дараа ийнхүү нийслэлийн засаг даргын туслалцаатайгаар гадаадын тамирчидтай хамт байрлах цэцэг зочид буудалдаа орж бэлтгэл сургуулиалтаа үргэлжүүлэх боломжтой нздтгазраас баг\n",
            "спорт\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
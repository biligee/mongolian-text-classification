{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mongolian text classification #04, RNN(LSTM).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "muNP8k9fqaJb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mongolian text classification series #01\n",
        "\n",
        "In this notebook I'm gonna try to classify cyrillic mongolian texts with LSTM.\n",
        "\n",
        "Eduge dataset provided by Bolorsoft LLC\n",
        "\n",
        "Author : Sharavsambuu Gunchinish (sharavsambuu@gmail.com)\n",
        "\n",
        "Github: https://github.com/sharavsambuu/mongolian-text-classification \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "iY9jwdg6qT8M",
        "colab_type": "code",
        "outputId": "70ae13ba-6931-476b-9d75-49ddb96c4bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "!pip install gensim\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.130)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.3.9)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.130 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.130)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "smJeJfoo4qcu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[More info about creation of eduge dataset pickles](https://github.com/sharavsambuu/mongolian-text-classification/blob/master/preprocess_dataset/preprocess_eduge.ipynb) preprocessing eats a lot of CPU cycle so it's good idea to cook it before using colab."
      ]
    },
    {
      "metadata": {
        "id": "CDayX_Yx3REh",
        "colab_type": "code",
        "outputId": "225460ef-a61d-486e-e831-6c132cd65f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "import sys\n",
        "\n",
        "def download_from_google_drive(file_id, file_name):\n",
        "  !rm -f ./cookie\n",
        "  !curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=$file_id\" > /dev/null\n",
        "  confirm_text = !awk '/download/ {print $NF}' ./cookie\n",
        "  confirm_text = confirm_text[0]\n",
        "  !curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=$confirm_text&id=$file_id\" -o $file_name\n",
        "  \n",
        "# download eduge pickles\n",
        "file_path = 'eduge_pickles'\n",
        "if not exists(file_path):\n",
        "  download_from_google_drive('1vjJ9YgIe8o0ErhbN0lH1XqPv3KFP8acv', '%s.rar' % file_path)\n",
        "  rar_file = file_path+\".rar\"\n",
        "  !unrar x $rar_file"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   388    0   388    0     0   4974      0 --:--:-- --:--:-- --:--:--  4974\n",
            "100  106M    0  106M    0     0   104M      0 --:--:--  0:00:01 --:--:--  231M\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from eduge_pickles.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file word_index.pickle\n",
            "9178153 bytes, modified on 2019-04-13 01:44\n",
            "with a new one\n",
            "9178153 bytes, modified on 2019-04-13 01:44\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit q\n",
            "\n",
            "Program aborted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pPHJcnfi4Rzg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('word_index.pickle', 'rb') as handle:\n",
        "  word_index = pickle.load(handle)\n",
        "    \n",
        "with open('reversed_word_index.pickle', 'rb') as handle:\n",
        "  reversed_word_index = pickle.load(handle)\n",
        "  \n",
        "with open('eduge_stopwords_removed.pickle', 'rb') as handle:\n",
        "  eduge_ds = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ASRW7ISNnbM-",
        "colab_type": "code",
        "outputId": "3db9b6a2-330f-400c-964c-60fb90b35182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# facebook trained word2vec on both commoncrawl and wikipedia. So this model should contain enough representation about our mongolian words.\n",
        "mongolian_word2vec_download=\"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.mn.300.bin.gz\"\n",
        "if not exists(\"cc.mn.300.bin.gz\"):\n",
        "  !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.mn.300.bin.gz\n",
        "if exists('cc.mn.300.bin.gz'):\n",
        "  !gunzip cc.mn.300.bin.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: cc.mn.300.bin already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BqGAauUZpnFz",
        "colab_type": "code",
        "outputId": "5efb56a9-8cae-44a4-8474-bc1db3d56564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.wrappers import FastText\n",
        "\n",
        "word2vec_model = FastText.load_fasttext_format('cc.mn.300.bin')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0414 01:07:52.334683 139997640750976 ssh.py:33] paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
            "W0414 01:07:52.809054 139997640750976 word2vec.py:573] Slow version of gensim.models.deprecated.word2vec is being used\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kkc1iiqJp-CJ",
        "colab_type": "code",
        "outputId": "99442697-27b5-4474-e384-f4f5c35dc7ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "print(word2vec_model.most_similar('монгол'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Монгол', 0.6342526078224182), ('монголын', 0.6047513484954834), ('хятад', 0.5558866858482361), ('Монголын', 0.5087883472442627), ('судлалаараа', 0.48851606249809265), ('манай', 0.4853793680667877), ('уйгаржин', 0.4725492596626282), ('угсаатангууд', 0.47093287110328674), ('орос', 0.46463483572006226), ('худам', 0.4609120190143585)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oF6vB3Qnq08I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# preparing embedding matrix\n",
        "import numpy as np\n",
        "\n",
        "words_not_found = []\n",
        "embed_dim       = 300\n",
        "embedding_matrix = np.random.uniform(-1, 1, (len(word_index), embed_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i<4:\n",
        "    continue\n",
        "  try:\n",
        "    embedding_vector = word2vec_model[word]\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "  except:\n",
        "    words_not_found.append(word)\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQAaXWIgsxm9",
        "colab_type": "code",
        "outputId": "d07b1789-a789-4089-ff5d-6a6b58ab8d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(embedding_matrix.shape)\n",
        "#print(embedding_matrix[5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(370794, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XFxd1QGR65VV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512\n",
        "\n",
        "import itertools\n",
        "\n",
        "for item in eduge_ds:\n",
        "  item[0] = list(itertools.chain(*item[0]))[:MAX_LEN]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U8PTeX0WCbhR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(eduge_ds, test_size=0.1, random_state=999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8mgMCFcgDHH4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_words  = [i[0] for i in train]\n",
        "train_label_words = [i[1] for i in train]\n",
        "test_data_words   = [i[0] for i in test ]\n",
        "test_label_words  = [i[1] for i in test ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rrXC7UiuFkCH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def encode_news(text):\n",
        "    return [word_index.get(i, 2) for i in text]\n",
        "  \n",
        "train_data = [encode_news(sent) for sent in train_data_words]\n",
        "test_data  = [encode_news(sent) for sent in test_data_words ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FV-h_avPEzM1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=MAX_LEN)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDVqmPqxIMid",
        "colab_type": "code",
        "outputId": "ec30beb7-996c-4508-8729-5d5111a96e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "labels = list(set(test_label_words))\n",
        "labels"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['спорт',\n",
              " 'эрүүл мэнд',\n",
              " 'урлаг соёл',\n",
              " 'эдийн засаг',\n",
              " 'байгал орчин',\n",
              " 'хууль',\n",
              " 'технологи',\n",
              " 'улс төр',\n",
              " 'боловсрол']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "PBKj3GQqJq29",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder     = LabelBinarizer()\n",
        "train_label = transfomed_label = encoder.fit_transform(train_label_words)\n",
        "test_label  = transfomed_label = encoder.fit_transform(test_label_words )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DPq45PN5HZ15",
        "colab_type": "code",
        "outputId": "16c06c24-94a0-4438-fa99-6c7e9cf9262c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_index)\n",
        "\n",
        "sequence_input     = keras.layers.Input(shape=(MAX_LEN,), dtype='int32')\n",
        "embedded_sequences = keras.layers.Embedding(\n",
        "    vocab_size, \n",
        "    embed_dim , \n",
        "    weights=[embedding_matrix], \n",
        "    input_length=MAX_LEN, \n",
        "    trainable=False)(sequence_input)\n",
        "x     = keras.layers.LSTM(128)(embedded_sequences)\n",
        "x     = keras.layers.Dense(245, activation='relu')(x)\n",
        "x     = keras.layers.Dropout(0.5)(x) # prevents overfitting\n",
        "preds = keras.layers.Dense(len(labels), activation='softmax')(x)\n",
        "\n",
        "model = keras.models.Model(sequence_input, preds)\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0414 01:09:45.882035 139997640750976 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f52c07278d0>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 512)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 512, 300)          111238200 \n",
            "_________________________________________________________________\n",
            "unified_lstm_1 (UnifiedLSTM) (None, 128)               219648    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 245)               31605     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 245)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 9)                 2214      \n",
            "=================================================================\n",
            "Total params: 111,491,667\n",
            "Trainable params: 253,467\n",
            "Non-trainable params: 111,238,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cAgP1KlqHu2F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPw8roFQKrHm",
        "colab_type": "code",
        "outputId": "869ebf0b-2b21-47c0-bc42-dbb1bb46efa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(train_data), len(train_label))\n",
        "print(len(test_data ), len(test_label) )\n",
        "\n",
        "partial_index = 3000\n",
        "\n",
        "x_val = train_data[:partial_index]\n",
        "partial_x_train = train_data[partial_index:]\n",
        "\n",
        "y_val = train_label[:partial_index]\n",
        "partial_y_train = train_label[partial_index:]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68094 68094\n",
            "7567 7567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iSTB4--RKacs",
        "colab_type": "code",
        "outputId": "da0e04a5-1f5a-41e7-d6f3-d8476069248a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1985
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs  ,\n",
        "                    batch_size=512 ,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 65094 samples, validate on 3000 samples\n",
            "Epoch 1/50\n",
            "65094/65094 [==============================] - 43s 657us/sample - loss: 2.1111 - accuracy: 0.1992 - val_loss: 2.0996 - val_accuracy: 0.2053\n",
            "Epoch 2/50\n",
            "65094/65094 [==============================] - 40s 613us/sample - loss: 2.0969 - accuracy: 0.2025 - val_loss: 2.7476 - val_accuracy: 0.1823\n",
            "Epoch 3/50\n",
            "65094/65094 [==============================] - 40s 610us/sample - loss: 2.0993 - accuracy: 0.2055 - val_loss: 2.0971 - val_accuracy: 0.2083\n",
            "Epoch 4/50\n",
            "65094/65094 [==============================] - 39s 606us/sample - loss: 2.1472 - accuracy: 0.2054 - val_loss: 2.0850 - val_accuracy: 0.2063\n",
            "Epoch 5/50\n",
            "65094/65094 [==============================] - 39s 607us/sample - loss: 2.1068 - accuracy: 0.2094 - val_loss: 2.0656 - val_accuracy: 0.2107\n",
            "Epoch 6/50\n",
            "65094/65094 [==============================] - 39s 605us/sample - loss: 2.0949 - accuracy: 0.2136 - val_loss: 2.1074 - val_accuracy: 0.2140\n",
            "Epoch 7/50\n",
            "65094/65094 [==============================] - 39s 605us/sample - loss: 2.0030 - accuracy: 0.2641 - val_loss: 1.9556 - val_accuracy: 0.3073\n",
            "Epoch 8/50\n",
            "65094/65094 [==============================] - 40s 607us/sample - loss: 1.9544 - accuracy: 0.3111 - val_loss: 1.9054 - val_accuracy: 0.3263\n",
            "Epoch 9/50\n",
            "65094/65094 [==============================] - 39s 604us/sample - loss: 1.9012 - accuracy: 0.3251 - val_loss: 2.1235 - val_accuracy: 0.2920\n",
            "Epoch 10/50\n",
            "65094/65094 [==============================] - 40s 607us/sample - loss: 1.8758 - accuracy: 0.3344 - val_loss: 1.7436 - val_accuracy: 0.3987\n",
            "Epoch 11/50\n",
            "65094/65094 [==============================] - 39s 603us/sample - loss: 1.7716 - accuracy: 0.3840 - val_loss: 1.7155 - val_accuracy: 0.4107\n",
            "Epoch 12/50\n",
            "65094/65094 [==============================] - 39s 604us/sample - loss: 1.7536 - accuracy: 0.3985 - val_loss: 1.7148 - val_accuracy: 0.4077\n",
            "Epoch 13/50\n",
            "65094/65094 [==============================] - 39s 604us/sample - loss: 1.7925 - accuracy: 0.3795 - val_loss: 1.8479 - val_accuracy: 0.3360\n",
            "Epoch 14/50\n",
            "65094/65094 [==============================] - 39s 603us/sample - loss: 1.7657 - accuracy: 0.3835 - val_loss: 1.7782 - val_accuracy: 0.3720\n",
            "Epoch 15/50\n",
            "65094/65094 [==============================] - 39s 604us/sample - loss: 1.8404 - accuracy: 0.3434 - val_loss: 1.8095 - val_accuracy: 0.3343\n",
            "Epoch 16/50\n",
            "65094/65094 [==============================] - 39s 600us/sample - loss: 1.8219 - accuracy: 0.3431 - val_loss: 1.8222 - val_accuracy: 0.3450\n",
            "Epoch 17/50\n",
            "65094/65094 [==============================] - 39s 604us/sample - loss: 1.7985 - accuracy: 0.3657 - val_loss: 1.6955 - val_accuracy: 0.4177\n",
            "Epoch 18/50\n",
            "65094/65094 [==============================] - 39s 602us/sample - loss: 1.7112 - accuracy: 0.4165 - val_loss: 1.7584 - val_accuracy: 0.3990\n",
            "Epoch 19/50\n",
            "65094/65094 [==============================] - 39s 606us/sample - loss: 1.7114 - accuracy: 0.4046 - val_loss: 1.8195 - val_accuracy: 0.3443\n",
            "Epoch 20/50\n",
            "65094/65094 [==============================] - 40s 607us/sample - loss: 1.8404 - accuracy: 0.3466 - val_loss: 1.8112 - val_accuracy: 0.3450\n",
            "Epoch 21/50\n",
            "65094/65094 [==============================] - 39s 604us/sample - loss: 1.7253 - accuracy: 0.3978 - val_loss: 1.6797 - val_accuracy: 0.4187\n",
            "Epoch 22/50\n",
            "65094/65094 [==============================] - 39s 602us/sample - loss: 1.6953 - accuracy: 0.4241 - val_loss: 1.6971 - val_accuracy: 0.4050\n",
            "Epoch 23/50\n",
            "65094/65094 [==============================] - 39s 603us/sample - loss: 1.7175 - accuracy: 0.4211 - val_loss: 1.7561 - val_accuracy: 0.3780\n",
            "Epoch 24/50\n",
            "65094/65094 [==============================] - 39s 604us/sample - loss: 1.6900 - accuracy: 0.4178 - val_loss: 2.1019 - val_accuracy: 0.3810\n",
            "Epoch 25/50\n",
            "65094/65094 [==============================] - 39s 604us/sample - loss: 1.7528 - accuracy: 0.3679 - val_loss: 1.9362 - val_accuracy: 0.2957\n",
            "Epoch 26/50\n",
            "65094/65094 [==============================] - 39s 604us/sample - loss: 1.7457 - accuracy: 0.3713 - val_loss: 1.7600 - val_accuracy: 0.3330\n",
            "Epoch 27/50\n",
            "25088/65094 [==========>...................] - ETA: 23s - loss: 1.7159 - accuracy: 0.3599"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2bf363790b0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    871\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "r8_mvDjYL3CX",
        "colab_type": "code",
        "outputId": "5b436b6c-914a-4787-b9f0-a81b12a2f67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_label)\n",
        "print(results)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7567/7567 [==============================] - 11s 1ms/sample - loss: 1.6580 - accuracy: 0.3986\n",
            "[1.6579768257694387, 0.39857274]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VaIioR7EPfig",
        "colab_type": "code",
        "outputId": "b5bbe828-3ace-4291-f762-5717df7d0bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "data_index   = 12\n",
        "data_words   = \" \".join(test_data_words[data_index])\n",
        "data_indexes = test_data[data_index]\n",
        "print(data_words)\n",
        "\n",
        "predicted = model.predict([[data_indexes]])\n",
        "print(encoder.classes_[np.argmax(predicted)])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "спортын төв ордонд өнөөдөр азийн оюутны аварга шалгаруулах эмэгтэй волейболчдын хоёр дахь удаагийн тэмцээний талаар мэдээлэл хийлээ анхны тэмцээн онд тайландын бангконг хотноо болж хоёрдугаар тэмцээнийг азийн оюутны спортын холбооноос аосх олгосон эрхийн дагуу оны дөрөвдүгээр сарын ны өдрүүдэд монгол улсын нийслэл улаанбаатар хотноо зохион байгуулах тэмцээний эрхийг монгол улс оны тавдугаар сарын хуралдсан аосхны гүйцэтгэх хорооны хурлаар хоёр оронтой өрсөлдөн авчээ уг тэмцээнийг монгол улсад авах талаар мосхолбоо оноос санаачлага гарган хөөцөлдөж эхэлсэн тэмцээний эрхийг авахад муын засгийн газрын санхүүгийн дэмжлэг мэргэжлийн холбоодын ажлын туршлага манай улсын олон улсын нэр хүнд ихээхэн тус хүргэжээ зохион байгуулах хороог с ламбаа удирдаж тэмцээний зохион байгуулах хороог збх эрүүл мэндийн сайдын оны тоот тушаалаар батлаж даргаар уихын гишүүн монголын волейболын холбооны мвх хүндэт ерөнхийлөгч сламбаа ажиллаж збхны орлогч даргаар згхагентлагбтсгын дарга чнаранбаатар збхны нарийн бичгийн даргаар монголын оюутны спортын холбооны мосх ерөнхий нарийн бичгийн дарга джаргалсайхан збхны гишүүдэд бсшуяны төрийн нарийн бичгийн дарга ддалайжаргал нийслэлийн здтгазрын дарга цболдсайхан сяны газрын дарга дбатжаргал гхяамны консулын газрын дарга дганхуяг бсшуяны мэргэжлийн боловсролын газрын дарга мбаасанжав гихалбаны дарга дмөрөн мосхны ерөнхийлөгч оуосхны ерөнхий санхүүч дбаясгалан муисийн ректор стөмөрочир мубисийн ректор бжадамба залуу монгол корпорацийн ерөнхийлөгч мсономпил мохны ерөнхий нарийн бичгийн дарга нбямбагэрэл мвхолбооны ерөнхий нарий бичгийн дарга цбатэнх миат хкийн маркетинг борлуулатын хэлтсийн дарга тмэндсайхан боловсрол суваг телевизийн ерөнхий захирал аамундра нар сонгогдон ажиллаж тэмцээнийг үнэ төлбөргүй үзүүлнэ волейболын болон оюутны спортыг сурталчилах дэлгэрүүлэх үүднээс тэмцээнийг үнэ төлбөргүй үзүүлэхээр збхорооны анхдугаар хурлаас шийдвэрлэсэн нийслэлийн иргэдийг тэмцээнийг өргөнөөр үзэхийг здтгазраас уриалсан тэмцээнийг зөвхөн улаанбаатар хотын иргэд бус аймгаас волейболын спортыг сонирхон хөгжөөн дэмжигч үзэгч волейболын спортын мэргэжилтэн багш нар секцэнд хичээллэгч хүүхдүүд зохион байгуулалтай ирэхээр ялангуяа тэмцээн болох газартай хамгийн ойрхон хануул дүүргийн здтгазар дүүргийнхээ ард иргэд хөдөлмөрчид сургуулийн сурагчид оюутнууд цэргийн албан хаагчид буянтухаа орчимын албан байгууллага хамт олныг идэвхтэй оролцуулах арга хэмжээ авч эхлэжээ олон зуун оюутнууд тэмцээн үзэх боллоо тэмцээний өдрүүдэд нийслэлээс буянтухаагийн спортын ордонг чиглэсэн хүмүүсийн цуваа ихсэх төлөвтэй учир нийслэлд үйл ажиллагаа явуулж байгаа орчим идсийн оюутнууд тэмцээнийг анги сургууль хамт олноороо үзэх сонирхолтой байгаагаа монголын оюутны холбоо биеийн тамирын тэнхимдээ хүсчээ үүний дагуу бсшуяам мох монголын оюутны спортын холбоо мосх ноос тэмцээнийг өдөр бүр гаруй сургуулийн орчим оюутнууд нэгдсэн хуваарийн дагуу үзэх хуваарийг бсшуяны төрийн нарийн бичгийн дарга зохион байгуулах үндэсний хороо збх ны гишүүн ддалайжаргал батлан сургуулиудад албан тоотоор хүргүүлжээ мосхд тэмцээнийг үзэхээр олон арван сургуулиуд оюутны тоогоо өгч бүртгүүлж суудлын хувиарлалтанд орж байгаа ажээ ялангуяа биеийн тамирын мэргэжлийн дээд сургуулийн оюутнууд дадлага хичээлээ тэмцээний үеэр хийхээр хичээлийн хувиараа зохицуулсан нийслэлийн засаг дарга оюутнуудад туслав улаанбаатар хотноо болдог оюутны олон улс тив дэлхийн тэмцээн бүрт нийслэлийн засаг дарга гмөнхбаяр ихээхэн туслалцаа үзүүлэн оюутан залуусаа байнга дэмжин оролцдог ажээ тэрээр тус тэмцээнд оролцохоор бэлтгэж байгаа монголын оюутны шигшээ багийн тамирчидын хоногийн бэлтгэл сургалтын зардлыг хариуцан гаргасан хөрөнгө санхүүгийн хүндрэлтэй байгаа үеэд тэмцээнд бэлтгэж байгаа оюутан тамирчидаа цагаа олж хэрэгцээтэй үеэд дэмжлээ мосхолбоо монголын волейболын холбоо мвх тамирчидынхаа өмнөөс талархал илэрхийлжээ монголын баг тамирчид эрдэнэт хотод оны сарын өдрөөс эхлэн хоногийн бэлтгэл хийснийхээ дараа ийнхүү нийслэлийн засаг даргын туслалцаатайгаар гадаадын тамирчидтай хамт байрлах цэцэг зочид буудалдаа орж бэлтгэл сургуулиалтаа үргэлжүүлэх боломжтой нздтгазраас баг\n",
            "спорт\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}